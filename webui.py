import pathlib
import sys
import uuid

import gradio as gr

from src.bilibili_downloader import extract_audio_from_video
from src.config import *
from src.core_process import (
    upload_audio, bilibili_video_download_process,
    process_multiple_urls, generate_subtitles_advanced
)
from src.task_manager import get_task_manager

# è·å–ä»»åŠ¡ç®¡ç†å™¨å®ä¾‹
task_manager = get_task_manager()


# ç»ˆæ­¢ä»»åŠ¡çš„è¾…åŠ©å‡½æ•°
def stop_task(task_id):
    """ç»ˆæ­¢æŒ‡å®šä»»åŠ¡"""
    if task_id:
        task_manager.stop_task(task_id)
        return f"å·²è¯·æ±‚ç»ˆæ­¢ä»»åŠ¡: {task_id}"
    return "æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡"


# ç”Ÿæˆå¹¶åˆ›å»ºä»»åŠ¡ID
def generate_task_id():
    """ç”Ÿæˆæ–°çš„ä»»åŠ¡IDå¹¶åœ¨ä»»åŠ¡ç®¡ç†å™¨ä¸­åˆ›å»º"""
    task_id = str(uuid.uuid4())
    task_manager.create_task(task_id)
    return task_id


# é…ç½®ç®¡ç†å‡½æ•°
def load_env_config():
    """ä».envæ–‡ä»¶åŠ è½½é…ç½®"""
    env_path = pathlib.Path(__file__).resolve().parent / ".env"
    config = {}
    if env_path.exists():
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    config[key.strip()] = value.strip()
    return config


def save_env_config(config_dict):
    """ä¿å­˜é…ç½®åˆ°.envæ–‡ä»¶"""
    env_path = pathlib.Path(__file__).resolve().parent / ".env"
    env_example_path = pathlib.Path(__file__).resolve().parent / ".env.example"

    # è¯»å–ç¤ºä¾‹æ–‡ä»¶ä»¥ä¿ç•™æ³¨é‡Šå’Œç»“æ„
    lines = []
    if env_example_path.exists():
        with open(env_example_path, 'r', encoding='utf-8') as f:
            written_keys = set()
            for line in f:
                line_stripped = line.strip()
                # å¦‚æœæ˜¯é…ç½®è¡Œï¼Œæ›´æ–°å€¼
                if line_stripped and not line_stripped.startswith('#') and '=' in line_stripped:
                    key = line_stripped.split('=', 1)[0].strip()
                    if key in config_dict:
                        # ä¿ç•™åŸå§‹ç¼©è¿›
                        indent = len(line) - len(line.lstrip())
                        lines.append(' ' * indent + f"{key}={config_dict[key]}\n")
                        written_keys.add(key)
                    else:
                        lines.append(line)
                else:
                    lines.append(line)

            # å°†ç¤ºä¾‹ä¸­æ²¡æœ‰ä½† config_dict æœ‰çš„é”®è¿½åŠ åˆ°æœ«å°¾ï¼Œä¿è¯æ–°é”®è¢«æŒä¹…åŒ–
            for key, value in config_dict.items():
                if key not in written_keys:
                    lines.append(f"{key}={value}\n")
    else:
        # å¦‚æœæ²¡æœ‰ç¤ºä¾‹æ–‡ä»¶ï¼Œç›´æ¥å†™å…¥é…ç½®
        for key, value in config_dict.items():
            lines.append(f"{key}={value}\n")

    with open(env_path, 'w', encoding='utf-8') as f:
        f.writelines(lines)

    return "é…ç½®å·²ä¿å­˜ï¼éœ€è¦é‡å¯åº”ç”¨ä»¥ä½¿é…ç½®ç”Ÿæ•ˆã€‚"


def update_config(
        # API Keys
        deepseek_key, gemini_key, dashscope_key, cerebras_key,
        # ç›®å½•
        output_dir, download_dir, temp_dir, model_dir, log_dir,
        # æ—¥å¿—
        log_level, log_file, log_console, log_colored, third_party_log_level,
        # ASR & è¾“å‡º
        asr_model, output_style, zip_enabled,
        # UI é»˜è®¤
        text_only_default,
        # LLM
        llm_server, llm_temp, llm_tokens, llm_top_p, llm_top_k, split_limit, async_flag,
        # æ‘˜è¦
        summary_server, summary_temp, summary_tokens,
        # åŠŸèƒ½å¼€å…³
        disable_polish, disable_summary, local_llm, debug_flag,
        # Web
        web_port
):
    """æ›´æ–°é…ç½®"""
    config = {
        "DEEPSEEK_API_KEY": deepseek_key,
        "GEMINI_API_KEY": gemini_key,
        "DASHSCOPE_API_KEY": dashscope_key,
        "CEREBRAS_API_KEY": cerebras_key,
        "OUTPUT_DIR": output_dir,
        "DOWNLOAD_DIR": download_dir,
        "TEMP_DIR": temp_dir,
        "MODEL_DIR": model_dir,
        "LOG_DIR": log_dir,
        "LOG_LEVEL": log_level,
        "LOG_FILE": log_file,
        "LOG_CONSOLE_OUTPUT": str(log_console).lower(),
        "LOG_COLORED_OUTPUT": str(log_colored).lower(),
        "THIRD_PARTY_LOG_LEVEL": third_party_log_level,
        "ASR_MODEL": asr_model,
        "OUTPUT_STYLE": output_style,
        "ZIP_OUTPUT_ENABLED": str(zip_enabled).lower(),
        "TEXT_ONLY_DEFAULT": str(text_only_default).lower(),
        "LLM_SERVER": llm_server,
        "LLM_TEMPERATURE": str(llm_temp),
        "LLM_MAX_TOKENS": str(llm_tokens),
        "LLM_TOP_P": str(llm_top_p),
        "LLM_TOP_K": str(llm_top_k),
        "SPLIT_LIMIT": str(split_limit),
        "ASYNC_FLAG": str(async_flag).lower(),
        "SUMMARY_LLM_SERVER": summary_server,
        "SUMMARY_LLM_TEMPERATURE": str(summary_temp),
        "SUMMARY_LLM_MAX_TOKENS": str(summary_tokens),
        "DISABLE_LLM_POLISH": str(disable_polish).lower(),
        "DISABLE_LLM_SUMMARY": str(disable_summary).lower(),
        "LOCAL_LLM_ENABLED": str(local_llm).lower(),
        "DEBUG_FLAG": str(debug_flag).lower(),
        "WEB_SERVER_PORT": str(web_port) if web_port else "",
    }
    return save_env_config(config)


def create_app():
    with gr.Blocks(title="éŸ³é¢‘è¯†åˆ«ä¸æ–‡æœ¬æ•´ç†å·¥å…·") as app:
        gr.Markdown("# ğŸ§ éŸ³é¢‘è¯†åˆ«ä¸æ–‡æœ¬æ•´ç†ç³»ç»Ÿ")
        gr.Markdown("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶æˆ–è¾“å…¥Bç«™è§†é¢‘é“¾æ¥ï¼Œä¸€é”®æå–æ–‡æœ¬å¹¶ç”Ÿæˆå›¾æ–‡ç‰ˆã€‚")
        # é¢„å…ˆåŠ è½½ .env é…ç½®ï¼Œç”¨äºè®¾ç½®å„ Tab é»˜è®¤å€¼ï¼ˆä¾‹å¦‚ TEXT_ONLY_DEFAULTï¼‰
        env_config = load_env_config()

        with gr.Tab("è¾“å…¥Bç«™é“¾æ¥"):
            # ä»»åŠ¡IDçŠ¶æ€
            task_id_state2 = gr.State(value=None)

            with gr.Row():
                bilibili_input = gr.Textbox(label="è¯·è¾“å…¥Bç«™è§†é¢‘é“¾æ¥")
            with gr.Row():
                llm_api_dropdown2 = gr.Dropdown(choices=LLM_SERVER_SUPPORTED, value=LLM_SERVER, label="é€‰æ‹©LLMæœåŠ¡")
                temp_slider2 = gr.Slider(0.0, 1.0, step=0.05, value=LLM_TEMPERATURE, label="Temperature")
                token_slider2 = gr.Slider(100, 8000, step=100, value=LLM_MAX_TOKENS, label="Max Tokens")
                # æ–°å¢ï¼šä»…è¿”å›çº¯æ–‡æœ¬(JSON)å¼€å…³
                text_only2 = gr.Checkbox(label="ä»…è¿”å›æ–‡æœ¬(JSON)",
                                         value=env_config.get("TEXT_ONLY_DEFAULT", "false").lower() == "true")
            with gr.Row():
                bilibili_button = gr.Button("ä¸‹è½½å¹¶å¤„ç†", variant="primary")
                stop_button2 = gr.Button("ç»ˆæ­¢ä»»åŠ¡", variant="stop")

            # æ–‡æœ¬å±•ç¤ºåŒºåŸŸ
            with gr.Accordion("ğŸ“ å¤„ç†ç»“æœæ–‡æœ¬", open=True):
                asr_text_output2 = gr.Textbox(label="ASR è¯†åˆ«æ–‡æœ¬", interactive=False, lines=8)
                polished_text_output2 = gr.Textbox(label="LLM æ¶¦è‰²æ–‡æœ¬", interactive=False, lines=8)
                summary_text_output2 = gr.Textbox(label="æ–‡æœ¬æ‘˜è¦", interactive=False, lines=6)

            bilibili_time = gr.Textbox(label="ä¸‹è½½+è¯†åˆ«+æ¶¦è‰²ç”¨æ—¶ï¼ˆç§’ï¼‰", interactive=False)
            stop_status2 = gr.Textbox(label="ç»ˆæ­¢çŠ¶æ€", interactive=False)

            with gr.Row():
                download_zip2 = gr.File(label="ä¸‹è½½æ‰“åŒ…ç»“æœï¼ˆZIPï¼‰", interactive=False)

            # åŒ…è£…å¤„ç†å‡½æ•°ï¼ˆæ¥æ”¶ task_id ä½œä¸ºå‚æ•°ï¼‰
            def bilibili_process_wrapper(url, llm_api, temp, tokens, text_only, task_id):
                # task_id å·²åœ¨å¤–éƒ¨ç”Ÿæˆå¹¶åˆ›å»º
                yield "å¤„ç†ä¸­...", "", "", "", None

                result = bilibili_video_download_process(url, llm_api, temp, tokens, text_only, task_id)
                # result = (result_data, extract_time, polish_time, zip_file)
                result_data, extract_time, polish_time, zip_file = result

                # å¤„ç†è¿”å›æ•°æ®
                if isinstance(result_data, dict):
                    asr_text = result_data.get("audio_text", "")
                    polished_text = result_data.get("polished_text", "")
                    summary_text = result_data.get("summary_text", "") or "æœªç”Ÿæˆæ‘˜è¦"
                else:
                    # é”™è¯¯æƒ…å†µ
                    asr_text = str(result_data)
                    polished_text = ""
                    summary_text = ""

                yield asr_text, polished_text, summary_text, extract_time, zip_file

            # å…ˆç”Ÿæˆ task_idï¼Œå†å¯åŠ¨å¤„ç†ï¼ˆç¡®ä¿ task_id å·²ä¿å­˜åˆ°çŠ¶æ€ï¼Œæ–¹ä¾¿ç»ˆæ­¢ï¼‰
            bilibili_button.click(
                fn=generate_task_id,
                inputs=[],
                outputs=[task_id_state2]
            ).then(
                fn=bilibili_process_wrapper,
                inputs=[bilibili_input, llm_api_dropdown2, temp_slider2, token_slider2, text_only2, task_id_state2],
                outputs=[asr_text_output2, polished_text_output2, summary_text_output2, bilibili_time, download_zip2]
            )

            stop_button2.click(
                fn=stop_task,
                inputs=[task_id_state2],
                outputs=[stop_status2]
            )

        with gr.Tab("æ‰¹é‡å¤„ç†Bç«™é“¾æ¥"):
            # ä»»åŠ¡IDçŠ¶æ€
            task_id_state3 = gr.State(value=None)

            with gr.Row():
                url_input = gr.Textbox(label="è¯·è¾“å…¥Bç«™è§†é¢‘é“¾æ¥ï¼Œæ¯ä¸ªURLæ¢è¡Œåˆ†éš”", lines=5,
                                       placeholder="ç¤ºä¾‹:\nhttps://www.bilibili.com/video/BV1...\nhttps://www.bilibili.com/video/BV2...")
            with gr.Row():
                llm_api_dropdown3 = gr.Dropdown(choices=LLM_SERVER_SUPPORTED, value=LLM_SERVER, label="é€‰æ‹©LLMæœåŠ¡")
                temp_slider3 = gr.Slider(0.0, 1.0, step=0.05, value=LLM_TEMPERATURE, label="Temperature")
                token_slider3 = gr.Slider(100, 8000, step=100, value=LLM_MAX_TOKENS, label="Max Tokens")
                # æ–°å¢ï¼šä»…è¿”å›çº¯æ–‡æœ¬(JSON)å¼€å…³
                text_only3 = gr.Checkbox(label="ä»…è¿”å›æ–‡æœ¬(JSON)",
                                         value=env_config.get("TEXT_ONLY_DEFAULT", "false").lower() == "true")
            with gr.Row():
                batch_button = gr.Button("æ‰¹é‡ä¸‹è½½å¹¶å¤„ç†", variant="primary")
                stop_button3 = gr.Button("ç»ˆæ­¢ä»»åŠ¡", variant="stop")

            batch_status = gr.Textbox(label="æ‰¹é‡å¤„ç†çŠ¶æ€", interactive=False, lines=5)
            batch_time = gr.Textbox(label="æ€»ä¸‹è½½+è¯†åˆ«+æ¶¦è‰²ç”¨æ—¶ï¼ˆç§’ï¼‰", interactive=False)
            stop_status3 = gr.Textbox(label="ç»ˆæ­¢çŠ¶æ€", interactive=False)

            with gr.Row():
                download_zip_batch = gr.File(label="ä¸‹è½½æ‰“åŒ…ç»“æœï¼ˆZIPï¼‰", interactive=False)

            # åŒ…è£…å¤„ç†å‡½æ•°ï¼ˆæ¥æ”¶ task_id ä½œä¸ºå‚æ•°ï¼‰
            def batch_process_wrapper(urls, llm_api, temp, tokens, text_only, task_id):
                # task_id å·²åœ¨å¤–éƒ¨ç”Ÿæˆå¹¶åˆ›å»º
                yield "æ‰¹é‡å¤„ç†ä¸­...", ""

                result = process_multiple_urls(urls, llm_api, temp, tokens, text_only, task_id)
                # result = (status_message, total_extract_time, total_polish_time, None, None, None)
                status_message = result[0]
                total_time = result[1]
                yield status_message, total_time

            # å…ˆç”Ÿæˆ task_idï¼Œå†å¯åŠ¨å¤„ç†ï¼ˆç¡®ä¿ task_id å·²ä¿å­˜åˆ°çŠ¶æ€ï¼Œæ–¹ä¾¿ç»ˆæ­¢ï¼‰
            batch_button.click(
                fn=generate_task_id,
                inputs=[],
                outputs=[task_id_state3]
            ).then(
                fn=batch_process_wrapper,
                inputs=[url_input, llm_api_dropdown3, temp_slider3, token_slider3, text_only3, task_id_state3],
                outputs=[batch_status, batch_time]
            )

            stop_button3.click(
                fn=stop_task,
                inputs=[task_id_state3],
                outputs=[stop_status3]
            )

        with gr.Tab("ä¸Šä¼ æœ¬åœ°éŸ³é¢‘æ–‡ä»¶"):
            # ä»»åŠ¡IDçŠ¶æ€
            task_id_state1 = gr.State(value=None)

            with gr.Row():
                audio_input = gr.File(label="é€‰æ‹©æœ¬åœ°éŸ³é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒmp3/wavæ ¼å¼ï¼‰")
            with gr.Row():
                llm_api_dropdown1 = gr.Dropdown(choices=LLM_SERVER_SUPPORTED, value=LLM_SERVER, label="é€‰æ‹©LLMæœåŠ¡")
                temp_slider1 = gr.Slider(0.0, 1.0, step=0.05, value=LLM_TEMPERATURE, label="Temperature")
                token_slider1 = gr.Slider(100, 8000, step=100, value=LLM_MAX_TOKENS, label="Max Tokens")
                # æ–°å¢ï¼šä»…è¿”å›çº¯æ–‡æœ¬(JSON)å¼€å…³
                text_only1 = gr.Checkbox(label="ä»…è¿”å›æ–‡æœ¬(JSON)",
                                         value=env_config.get("TEXT_ONLY_DEFAULT", "false").lower() == "true")
            with gr.Row():
                upload_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
                stop_button1 = gr.Button("ç»ˆæ­¢ä»»åŠ¡", variant="stop")

            # æ–‡æœ¬å±•ç¤ºåŒºåŸŸ
            with gr.Accordion("ğŸ“ å¤„ç†ç»“æœæ–‡æœ¬", open=True):
                asr_text_output1 = gr.Textbox(label="ASR è¯†åˆ«æ–‡æœ¬", interactive=False, lines=8)
                polished_text_output1 = gr.Textbox(label="LLM æ¶¦è‰²æ–‡æœ¬", interactive=False, lines=8)
                summary_text_output1 = gr.Textbox(label="æ–‡æœ¬æ‘˜è¦", interactive=False, lines=6)

            upload_time = gr.Textbox(label="è¯†åˆ«+æ¶¦è‰²ç”¨æ—¶ï¼ˆç§’ï¼‰", interactive=False)
            stop_status1 = gr.Textbox(label="ç»ˆæ­¢çŠ¶æ€", interactive=False)

            with gr.Row():
                download_zip1 = gr.File(label="ä¸‹è½½æ‰“åŒ…ç»“æœï¼ˆZIPï¼‰", interactive=False)

            # åŒ…è£…å¤„ç†å‡½æ•°ï¼ˆæ¥æ”¶ task_id ä½œä¸ºå‚æ•°ï¼‰
            def upload_process_wrapper(audio_file, llm_api, temp, tokens, text_only, task_id):
                # task_id å·²åœ¨å¤–éƒ¨ç”Ÿæˆå¹¶åˆ›å»º
                yield "å¤„ç†ä¸­...", "", "", "", None

                result = upload_audio(audio_file, llm_api, temp, tokens, text_only, task_id)
                # result = (result_data, extract_time, polish_time, zip_file)
                result_data, extract_time, polish_time, zip_file = result

                # å¤„ç†è¿”å›æ•°æ®
                if isinstance(result_data, dict):
                    asr_text = result_data.get("audio_text", "")
                    polished_text = result_data.get("polished_text", "")
                    summary_text = result_data.get("summary_text", "") or "æœªç”Ÿæˆæ‘˜è¦"
                else:
                    # é”™è¯¯æƒ…å†µ
                    asr_text = str(result_data)
                    polished_text = ""
                    summary_text = ""

                yield asr_text, polished_text, summary_text, extract_time, zip_file

            # å…ˆç”Ÿæˆ task_idï¼Œå†å¯åŠ¨å¤„ç†ï¼ˆç¡®ä¿ task_id å·²ä¿å­˜åˆ°çŠ¶æ€ï¼Œæ–¹ä¾¿ç»ˆæ­¢ï¼‰
            upload_button.click(
                fn=generate_task_id,
                inputs=[],
                outputs=[task_id_state1]
            ).then(
                fn=upload_process_wrapper,
                inputs=[audio_input, llm_api_dropdown1, temp_slider1, token_slider1, text_only1, task_id_state1],
                outputs=[asr_text_output1, polished_text_output1, summary_text_output1, upload_time, download_zip1]
            )

            stop_button1.click(
                fn=stop_task,
                inputs=[task_id_state1],
                outputs=[stop_status1]
            )

        with gr.Tab("ä¸Šä¼ æœ¬åœ°è§†é¢‘æ–‡ä»¶"):
            # ä»»åŠ¡IDçŠ¶æ€
            task_id_state_video = gr.State(value=None)

            with gr.Row():
                video_input2 = gr.File(label="é€‰æ‹©æœ¬åœ°è§†é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒmp4æ ¼å¼ï¼‰")
            with gr.Row():
                video_button = gr.Button("æå–éŸ³é¢‘å¹¶å¤„ç†", variant="primary")
                stop_button_video = gr.Button("ç»ˆæ­¢ä»»åŠ¡", variant="stop")

            # æ–‡æœ¬å±•ç¤ºåŒºåŸŸ
            with gr.Accordion("ğŸ“ å¤„ç†ç»“æœæ–‡æœ¬", open=True):
                asr_text_output_video = gr.Textbox(label="ASR è¯†åˆ«æ–‡æœ¬", interactive=False, lines=8)
                polished_text_output_video = gr.Textbox(label="LLM æ¶¦è‰²æ–‡æœ¬", interactive=False, lines=8)
                summary_text_output_video = gr.Textbox(label="æ–‡æœ¬æ‘˜è¦", interactive=False, lines=6)

            video_time = gr.Textbox(label="æå–+è¯†åˆ«+æ¶¦è‰²ç”¨æ—¶ï¼ˆç§’ï¼‰", interactive=False)
            stop_status_video = gr.Textbox(label="ç»ˆæ­¢çŠ¶æ€", interactive=False)

            with gr.Row():
                download_zip_video = gr.File(label="ä¸‹è½½æ‰“åŒ…ç»“æœï¼ˆZIPï¼‰", interactive=False)

            # åŒ…è£…å¤„ç†å‡½æ•°ï¼ˆæ¥æ”¶ task_id ä½œä¸ºå‚æ•°ï¼‰
            def video_process_wrapper(vf, api, temp, tokens, text_only, task_id):
                if vf:
                    # task_id å·²åœ¨å¤–éƒ¨ç”Ÿæˆå¹¶åˆ›å»º
                    yield "æå–éŸ³é¢‘å¹¶å¤„ç†ä¸­...", "", "", "", None

                    result = upload_audio(
                        extract_audio_from_video(vf), api, temp, tokens, text_only, task_id
                    )
                    # result = (result_data, extract_time, polish_time, zip_file)
                    result_data, extract_time, polish_time, zip_file = result

                    # å¤„ç†è¿”å›æ•°æ®
                    if isinstance(result_data, dict):
                        asr_text = result_data.get("audio_text", "")
                        polished_text = result_data.get("polished_text", "")
                        summary_text = result_data.get("summary_text", "") or "æœªç”Ÿæˆæ‘˜è¦"
                    else:
                        # é”™è¯¯æƒ…å†µ
                        asr_text = str(result_data)
                        polished_text = ""
                        summary_text = ""

                    total_time = extract_time + polish_time if isinstance(polish_time, (int, float)) else extract_time
                    yield asr_text, polished_text, summary_text, total_time, zip_file
                else:
                    yield "è¯·ä¸Šä¼ ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ã€‚", "", "", None, None

            # å…ˆç”Ÿæˆ task_idï¼Œå†å¯åŠ¨å¤„ç†ï¼ˆç¡®ä¿ task_id å·²ä¿å­˜åˆ°çŠ¶æ€ï¼Œæ–¹ä¾¿ç»ˆæ­¢ï¼‰
            video_button.click(
                fn=generate_task_id,
                inputs=[],
                outputs=[task_id_state_video]
            ).then(
                fn=video_process_wrapper,
                inputs=[video_input2, llm_api_dropdown1, temp_slider1, token_slider1, text_only1, task_id_state_video],
                outputs=[asr_text_output_video, polished_text_output_video, summary_text_output_video, video_time,
                         download_zip_video]
            )

            stop_button_video.click(
                fn=stop_task,
                inputs=[task_id_state_video],
                outputs=[stop_status_video]
            )

        with gr.Tab("å­—å¹•ç”Ÿæˆ"):
            gr.Markdown("## ğŸ¬ å­—å¹•ç”Ÿæˆå·¥å…·")
            gr.Markdown("ä¸Šä¼ éŸ³é¢‘æˆ–è§†é¢‘æ–‡ä»¶ï¼Œè‡ªåŠ¨ç”Ÿæˆå­—å¹•æ–‡ä»¶ã€‚æ”¯æŒå¤šç§ ASR æ¨¡å‹å’Œåˆ†æ®µç­–ç•¥ã€‚")

            # ä»»åŠ¡IDçŠ¶æ€
            task_id_state_subtitle = gr.State(value=None)

            with gr.Row():
                media_input = gr.File(label="é€‰æ‹©åª’ä½“æ–‡ä»¶ï¼ˆæ”¯æŒéŸ³é¢‘ï¼šmp3/wav/flac æˆ– è§†é¢‘ï¼šmp4/avi/movï¼‰")

            with gr.Accordion("åŸºæœ¬è®¾ç½®", open=True):
                with gr.Row():
                    file_type = gr.Dropdown(
                        choices=['srt', 'cc'],
                        value='srt',
                        label="å­—å¹•æ ¼å¼"
                    )
                    asr_model = gr.Dropdown(
                        choices=['paraformer', 'sense_voice'],
                        value='paraformer',
                        label="ASR æ¨¡å‹"
                    )

                with gr.Row():
                    segmenter_type = gr.Dropdown(
                        choices=[
                            ('ä»…åœé¡¿', 'pause'),
                            ('æ ‡ç‚¹ç¬¦å· + åœé¡¿ï¼ˆæ¨èï¼‰', 'punctuation'),
                            ('LLM æ™ºèƒ½åˆ†æ®µ', 'llm')
                        ],
                        value='punctuation',
                        label="åˆ†æ®µç­–ç•¥",
                        info="punctuation: ä¼˜å…ˆä½¿ç”¨æ ‡ç‚¹ç¬¦å·åˆ†æ®µï¼Œæ›´è‡ªç„¶"
                    )
                    output_type = gr.Dropdown(
                        choices=[
                            ('ä»…ç”Ÿæˆå­—å¹•æ–‡ä»¶', 'subtitle_only'),
                            ('ç”Ÿæˆå­—å¹• + ç¡¬ç¼–ç åˆ°è§†é¢‘', 'video_with_subtitle')
                        ],
                        value='subtitle_only',
                        label="è¾“å‡ºç±»å‹",
                        info="ç¡¬ç¼–ç ä»…æ”¯æŒè§†é¢‘æ–‡ä»¶å’Œ SRT æ ¼å¼"
                    )

            with gr.Accordion("é«˜çº§è®¾ç½®", open=False):
                with gr.Row():
                    llm_api_dropdown_subtitle = gr.Dropdown(
                        choices=LLM_SERVER_SUPPORTED,
                        value=LLM_SERVER,
                        label="LLM æœåŠ¡ï¼ˆç”¨äº LLM åˆ†æ®µï¼‰"
                    )

                with gr.Row():
                    pause_threshold = gr.Slider(
                        minimum=0.1,
                        maximum=2.0,
                        step=0.1,
                        value=0.6,
                        label="åœé¡¿é˜ˆå€¼ï¼ˆç§’ï¼‰",
                        info="ç”¨äºåŸºäºåœé¡¿çš„åˆ†æ®µ"
                    )
                    max_chars = gr.Slider(
                        minimum=10,
                        maximum=30,
                        step=1,
                        value=16,
                        label="æ¯æ®µæœ€å¤§å­—ç¬¦æ•°"
                    )

                with gr.Row():
                    batch_size_s = gr.Slider(
                        minimum=1,
                        maximum=30,
                        step=1,
                        value=5,
                        label="SenseVoice æ‰¹å¤„ç†å¤§å°ï¼ˆç§’ï¼‰",
                        info="SenseVoice æ¨¡å‹ä½¿ç”¨"
                    )
                    paraformer_chunk_size_s = gr.Slider(
                        minimum=10,
                        maximum=120,
                        step=10,
                        value=30,
                        label="Paraformer åˆ†å—å¤§å°ï¼ˆç§’ï¼‰",
                        info="Paraformer æ¨¡å‹éŸ³é¢‘åˆ†å—å¤§å°ï¼Œå½±å“æ—¶é—´ç²¾åº¦"
                    )

            with gr.Row():
                subtitle_gen_button = gr.Button("ğŸ¬ å¼€å§‹ç”Ÿæˆå­—å¹•", variant="primary", size="lg")
                stop_button_subtitle = gr.Button("ğŸ›‘ ç»ˆæ­¢ä»»åŠ¡", variant="stop")

            with gr.Row():
                subtitle_status = gr.Textbox(
                    label="å¤„ç†çŠ¶æ€",
                    interactive=False,
                    lines=5
                )

            with gr.Row():
                with gr.Column():
                    subtitle_file_output = gr.File(label="ğŸ“„ ä¸‹è½½å­—å¹•æ–‡ä»¶", interactive=False)
                with gr.Column():
                    video_with_subtitle_output = gr.File(label="ğŸ¥ ä¸‹è½½å¸¦å­—å¹•è§†é¢‘", interactive=False)

            stop_status_subtitle = gr.Textbox(label="ç»ˆæ­¢çŠ¶æ€", interactive=False)

            # åŒ…è£…å¤„ç†å‡½æ•°ï¼ˆæ¥æ”¶ task_id ä½œä¸ºå‚æ•°ï¼‰
            def subtitle_gen_wrapper(
                    media_file,
                    file_type,
                    model,
                    segmenter_type,
                    output_type,
                    llm_api,
                    pause_threshold,
                    max_chars,
                    batch_size_s,
                    paraformer_chunk_size_s,
                    task_id
            ):
                if media_file is None:
                    yield "è¯·ä¸Šä¼ åª’ä½“æ–‡ä»¶", None, None
                    return

                # task_id å·²åœ¨å¤–éƒ¨ç”Ÿæˆå¹¶åˆ›å»º
                yield "æ­£åœ¨ç”Ÿæˆå­—å¹•...", None, None

                subtitle_path, video_path, info = generate_subtitles_advanced(
                    media_file=media_file,
                    file_type=file_type,
                    model=model,
                    segmenter_type=segmenter_type,
                    output_type=output_type,
                    api_server=llm_api if segmenter_type == 'llm' else None,
                    pause_threshold=pause_threshold,
                    max_chars=max_chars,
                    batch_size_s=batch_size_s,
                    paraformer_chunk_size_s=paraformer_chunk_size_s,
                    task_id=task_id
                )
                yield info, subtitle_path, video_path

            # å…ˆç”Ÿæˆ task_idï¼Œå†å¯åŠ¨å¤„ç†ï¼ˆç¡®ä¿ task_id å·²ä¿å­˜åˆ°çŠ¶æ€ï¼Œæ–¹ä¾¿ç»ˆæ­¢ï¼‰
            subtitle_gen_button.click(
                fn=generate_task_id,
                inputs=[],
                outputs=[task_id_state_subtitle]
            ).then(
                fn=subtitle_gen_wrapper,
                inputs=[
                    media_input,
                    file_type,
                    asr_model,
                    segmenter_type,
                    output_type,
                    llm_api_dropdown_subtitle,
                    pause_threshold,
                    max_chars,
                    batch_size_s,
                    paraformer_chunk_size_s,
                    task_id_state_subtitle
                ],
                outputs=[
                    subtitle_status,
                    subtitle_file_output,
                    video_with_subtitle_output
                ]
            )

            stop_button_subtitle.click(
                fn=stop_task,
                inputs=[task_id_state_subtitle],
                outputs=[stop_status_subtitle]
            )

        with gr.Tab("ç³»ç»Ÿé…ç½®"):
            gr.Markdown("## é…ç½®ç®¡ç†")
            gr.Markdown("åœ¨è¿™é‡Œä¿®æ”¹ç³»ç»Ÿé…ç½®ï¼Œä¿å­˜åéœ€è¦é‡å¯åº”ç”¨æ‰èƒ½ç”Ÿæ•ˆã€‚")

            # åŠ è½½å½“å‰é…ç½®
            # env_config = load_env_config()

            with gr.Accordion("API Keys", open=True):
                deepseek_key = gr.Textbox(
                    label="DeepSeek API Key",
                    value=env_config.get("DEEPSEEK_API_KEY", ""),
                    type="password"
                )
                gemini_key = gr.Textbox(
                    label="Gemini API Key",
                    value=env_config.get("GEMINI_API_KEY", ""),
                    type="password"
                )
                dashscope_key = gr.Textbox(
                    label="DashScope API Key (é€šä¹‰åƒé—®)",
                    value=env_config.get("DASHSCOPE_API_KEY", ""),
                    type="password"
                )
                cerebras_key = gr.Textbox(
                    label="Cerebras API Key",
                    value=env_config.get("CEREBRAS_API_KEY", ""),
                    type="password"
                )

            with gr.Accordion("ç›®å½•é…ç½®", open=False):
                output_dir = gr.Textbox(
                    label="è¾“å‡ºç›®å½•",
                    value=env_config.get("OUTPUT_DIR", "./out")
                )
                download_dir = gr.Textbox(
                    label="ä¸‹è½½ç›®å½•",
                    value=env_config.get("DOWNLOAD_DIR", "./download")
                )
                temp_dir = gr.Textbox(
                    label="ä¸´æ—¶ç›®å½•",
                    value=env_config.get("TEMP_DIR", "./temp")
                )
                model_dir = gr.Textbox(
                    label="æ¨¡å‹ç›®å½•ï¼ˆç•™ç©ºä½¿ç”¨é»˜è®¤ï¼‰",
                    value=env_config.get("MODEL_DIR", "")
                )
                log_dir = gr.Textbox(
                    label="æ—¥å¿—ç›®å½•",
                    value=env_config.get("LOG_DIR", "./logs")
                )

            with gr.Accordion("æ—¥å¿—é…ç½®", open=False):
                log_level = gr.Dropdown(
                    choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
                    label="æ—¥å¿—çº§åˆ«",
                    value=env_config.get("LOG_LEVEL", "INFO")
                )
                log_file = gr.Textbox(
                    label="æ—¥å¿—æ–‡ä»¶è·¯å¾„",
                    value=env_config.get("LOG_FILE", "./logs/AutoVoiceCollation.log")
                )
                log_console = gr.Checkbox(
                    label="è¾“å‡ºåˆ°æ§åˆ¶å°",
                    value=env_config.get("LOG_CONSOLE_OUTPUT", "true").lower() == "true"
                )
                log_colored = gr.Checkbox(
                    label="å½©è‰²è¾“å‡º",
                    value=env_config.get("LOG_COLORED_OUTPUT", "true").lower() == "true"
                )
                third_party_log_level = gr.Dropdown(
                    choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
                    label="ç¬¬ä¸‰æ–¹åº“æ—¥å¿—çº§åˆ«",
                    value=env_config.get("THIRD_PARTY_LOG_LEVEL", "ERROR")
                )

            with gr.Accordion("ASR å’Œè¾“å‡ºé…ç½®", open=False):
                asr_model = gr.Dropdown(
                    choices=["paraformer", "sense_voice"],
                    label="ASR æ¨¡å‹",
                    value=env_config.get("ASR_MODEL", "paraformer")
                )
                output_style = gr.Dropdown(
                    choices=["pdf_with_img", "img_only", "text_only", "pdf_only"],
                    label="è¾“å‡ºæ ·å¼",
                    value=env_config.get("OUTPUT_STYLE", "pdf_only")
                )
                zip_enabled = gr.Checkbox(
                    label="å¯ç”¨ ZIP å‹ç¼©è¾“å‡º",
                    value=env_config.get("ZIP_OUTPUT_ENABLED", "false").lower() == "true"
                )
                # æ–°å¢ï¼šè®°ä½ Web UI ä¸­ text_only çš„é»˜è®¤å€¼
                text_only_default = gr.Checkbox(
                    label="é»˜è®¤ä»…è¿”å›æ–‡æœ¬(JSON)",
                    value=env_config.get("TEXT_ONLY_DEFAULT", "false").lower() == "true"
                )

            with gr.Accordion("LLM é…ç½®", open=False):
                llm_server = gr.Dropdown(
                    choices=LLM_SERVER_SUPPORTED,
                    label="LLM æœåŠ¡",
                    value=env_config.get("LLM_SERVER", "Cerebras:Qwen-3-235B-Instruct")
                )
                llm_temp = gr.Slider(
                    minimum=0.0,
                    maximum=2.0,
                    step=0.05,
                    label="Temperature",
                    value=float(env_config.get("LLM_TEMPERATURE", "0.1"))
                )
                llm_tokens = gr.Slider(
                    minimum=100,
                    maximum=8000,
                    step=100,
                    label="Max Tokens",
                    value=int(env_config.get("LLM_MAX_TOKENS", "6000"))
                )
                llm_top_p = gr.Slider(
                    minimum=0.0,
                    maximum=1.0,
                    step=0.01,
                    label="Top P",
                    value=float(env_config.get("LLM_TOP_P", "0.95"))
                )
                llm_top_k = gr.Slider(
                    minimum=0,
                    maximum=100,
                    step=1,
                    label="Top K",
                    value=int(env_config.get("LLM_TOP_K", "64"))
                )
                split_limit = gr.Slider(
                    minimum=100,
                    maximum=5000,
                    step=100,
                    label="æ–‡æœ¬åˆ†æ®µé•¿åº¦",
                    value=int(env_config.get("SPLIT_LIMIT", "1000"))
                )
                async_flag = gr.Checkbox(
                    label="å¯ç”¨å¼‚æ­¥å¤„ç†",
                    value=env_config.get("ASYNC_FLAG", "true").lower() == "true"
                )

            with gr.Accordion("æ‘˜è¦ç”Ÿæˆé…ç½®", open=False):
                summary_server = gr.Dropdown(
                    choices=LLM_SERVER_SUPPORTED,
                    label="æ‘˜è¦ LLM æœåŠ¡",
                    value=env_config.get("SUMMARY_LLM_SERVER", "Cerebras:Qwen-3-235B-Thinking")
                )
                summary_temp = gr.Slider(
                    minimum=0.0,
                    maximum=2.0,
                    step=0.05,
                    label="æ‘˜è¦ Temperature",
                    value=float(env_config.get("SUMMARY_LLM_TEMPERATURE", "1.0"))
                )
                summary_tokens = gr.Slider(
                    minimum=100,
                    maximum=16000,
                    step=100,
                    label="æ‘˜è¦ Max Tokens",
                    value=int(env_config.get("SUMMARY_LLM_MAX_TOKENS", "8192"))
                )

            with gr.Accordion("åŠŸèƒ½å¼€å…³", open=False):
                disable_polish = gr.Checkbox(
                    label="ç¦ç”¨ LLM æ¶¦è‰²",
                    value=env_config.get("DISABLE_LLM_POLISH", "false").lower() == "true"
                )
                disable_summary = gr.Checkbox(
                    label="ç¦ç”¨ LLM æ‘˜è¦",
                    value=env_config.get("DISABLE_LLM_SUMMARY", "false").lower() == "true"
                )
                local_llm = gr.Checkbox(
                    label="å¯ç”¨æœ¬åœ° LLM",
                    value=env_config.get("LOCAL_LLM_ENABLED", "false").lower() == "true"
                )
                debug_flag = gr.Checkbox(
                    label="è°ƒè¯•æ¨¡å¼",
                    value=env_config.get("DEBUG_FLAG", "false").lower() == "true"
                )

            with gr.Accordion("Web æœåŠ¡å™¨é…ç½®", open=False):
                web_port = gr.Number(
                    label="Web æœåŠ¡å™¨ç«¯å£ï¼ˆç•™ç©ºä¸ºè‡ªåŠ¨ï¼‰",
                    value=int(env_config.get("WEB_SERVER_PORT", "0")) if env_config.get("WEB_SERVER_PORT",
                                                                                        "") else None,
                    precision=0
                )

            # ä¿å­˜æŒ‰é’®å’ŒçŠ¶æ€æ˜¾ç¤º
            save_button = gr.Button("ä¿å­˜é…ç½®", variant="primary", size="lg")
            save_status = gr.Textbox(label="ä¿å­˜çŠ¶æ€", interactive=False)

            # ç»‘å®šä¿å­˜äº‹ä»¶
            save_button.click(
                fn=update_config,
                inputs=[
                    deepseek_key, gemini_key, dashscope_key, cerebras_key,
                    output_dir, download_dir, temp_dir, model_dir, log_dir,
                    log_level, log_file, log_console, log_colored, third_party_log_level,
                    asr_model, output_style, zip_enabled, text_only_default,
                    llm_server, llm_temp, llm_tokens, llm_top_p, llm_top_k, split_limit, async_flag,
                    summary_server, summary_temp, summary_tokens,
                    disable_polish, disable_summary, local_llm, debug_flag,
                    web_port
                ],
                outputs=[save_status]
            )

    return app


def launch_ui(server_name: str = "0.0.0.0", server_port: int | None = None, share: bool = False):
    app = create_app()
    # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå…¶æ¬¡ä½¿ç”¨é…ç½®ä¸­çš„ WEB_SERVER_PORTï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå¦åˆ™è®© gradio è‡ªåŠ¨é€‰æ‹©
    port = server_port or (
        int(WEB_SERVER_PORT) if (globals().get('WEB_SERVER_PORT') and str(WEB_SERVER_PORT).strip()) else None)
    should_launch_browser = '--from-electron' not in sys.argv
    app.launch(server_name=server_name, server_port=port, share=share, inbrowser=should_launch_browser)


if __name__ == "__main__":
    launch_ui()
