import pathlib
import sys

import gradio as gr

from config import *
from src.bilibili_downloader import extract_audio_from_video
from src.core_process import (
    upload_audio, bilibili_video_download_process,
    process_multiple_urls, process_subtitles
)


# é…ç½®ç®¡ç†å‡½æ•°
def load_env_config():
    """ä».envæ–‡ä»¶åŠ è½½é…ç½®"""
    env_path = pathlib.Path(__file__).resolve().parent / ".env"
    config = {}
    if env_path.exists():
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    config[key.strip()] = value.strip()
    return config


def save_env_config(config_dict):
    """ä¿å­˜é…ç½®åˆ°.envæ–‡ä»¶"""
    env_path = pathlib.Path(__file__).resolve().parent / ".env"
    env_example_path = pathlib.Path(__file__).resolve().parent / ".env.example"

    # è¯»å–ç¤ºä¾‹æ–‡ä»¶ä»¥ä¿ç•™æ³¨é‡Šå’Œç»“æ„
    lines = []
    if env_example_path.exists():
        with open(env_example_path, 'r', encoding='utf-8') as f:
            written_keys = set()
            for line in f:
                line_stripped = line.strip()
                # å¦‚æœæ˜¯é…ç½®è¡Œï¼Œæ›´æ–°å€¼
                if line_stripped and not line_stripped.startswith('#') and '=' in line_stripped:
                    key = line_stripped.split('=', 1)[0].strip()
                    if key in config_dict:
                        # ä¿ç•™åŸå§‹ç¼©è¿›
                        indent = len(line) - len(line.lstrip())
                        lines.append(' ' * indent + f"{key}={config_dict[key]}\n")
                        written_keys.add(key)
                    else:
                        lines.append(line)
                else:
                    lines.append(line)

            # å°†ç¤ºä¾‹ä¸­æ²¡æœ‰ä½† config_dict æœ‰çš„é”®è¿½åŠ åˆ°æœ«å°¾ï¼Œä¿è¯æ–°é”®è¢«æŒä¹…åŒ–
            for key, value in config_dict.items():
                if key not in written_keys:
                    lines.append(f"{key}={value}\n")
    else:
        # å¦‚æœæ²¡æœ‰ç¤ºä¾‹æ–‡ä»¶ï¼Œç›´æ¥å†™å…¥é…ç½®
        for key, value in config_dict.items():
            lines.append(f"{key}={value}\n")

    with open(env_path, 'w', encoding='utf-8') as f:
        f.writelines(lines)

    return "é…ç½®å·²ä¿å­˜ï¼éœ€è¦é‡å¯åº”ç”¨ä»¥ä½¿é…ç½®ç”Ÿæ•ˆã€‚"


def update_config(
        # API Keys
        deepseek_key, gemini_key, dashscope_key, cerebras_key,
        # ç›®å½•
        output_dir, download_dir, temp_dir, model_dir, log_dir,
        # æ—¥å¿—
        log_level, log_file, log_console, log_colored, third_party_log_level,
        # ASR & è¾“å‡º
        asr_model, output_style, zip_enabled,
        # UI é»˜è®¤
        text_only_default,
        # LLM
        llm_server, llm_temp, llm_tokens, llm_top_p, llm_top_k, split_limit, async_flag,
        # æ‘˜è¦
        summary_server, summary_temp, summary_tokens,
        # åŠŸèƒ½å¼€å…³
        disable_polish, disable_summary, local_llm, debug_flag,
        # Web
        web_port
):
    """æ›´æ–°é…ç½®"""
    config = {
        "DEEPSEEK_API_KEY": deepseek_key,
        "GEMINI_API_KEY": gemini_key,
        "DASHSCOPE_API_KEY": dashscope_key,
        "CEREBRAS_API_KEY": cerebras_key,
        "OUTPUT_DIR": output_dir,
        "DOWNLOAD_DIR": download_dir,
        "TEMP_DIR": temp_dir,
        "MODEL_DIR": model_dir,
        "LOG_DIR": log_dir,
        "LOG_LEVEL": log_level,
        "LOG_FILE": log_file,
        "LOG_CONSOLE_OUTPUT": str(log_console).lower(),
        "LOG_COLORED_OUTPUT": str(log_colored).lower(),
        "THIRD_PARTY_LOG_LEVEL": third_party_log_level,
        "ASR_MODEL": asr_model,
        "OUTPUT_STYLE": output_style,
        "ZIP_OUTPUT_ENABLED": str(zip_enabled).lower(),
        "TEXT_ONLY_DEFAULT": str(text_only_default).lower(),
        "LLM_SERVER": llm_server,
        "LLM_TEMPERATURE": str(llm_temp),
        "LLM_MAX_TOKENS": str(llm_tokens),
        "LLM_TOP_P": str(llm_top_p),
        "LLM_TOP_K": str(llm_top_k),
        "SPLIT_LIMIT": str(split_limit),
        "ASYNC_FLAG": str(async_flag).lower(),
        "SUMMARY_LLM_SERVER": summary_server,
        "SUMMARY_LLM_TEMPERATURE": str(summary_temp),
        "SUMMARY_LLM_MAX_TOKENS": str(summary_tokens),
        "DISABLE_LLM_POLISH": str(disable_polish).lower(),
        "DISABLE_LLM_SUMMARY": str(disable_summary).lower(),
        "LOCAL_LLM_ENABLED": str(local_llm).lower(),
        "DEBUG_FLAG": str(debug_flag).lower(),
        "WEB_SERVER_PORT": str(web_port) if web_port else "",
    }
    return save_env_config(config)


def create_app():
    with gr.Blocks(title="éŸ³é¢‘è¯†åˆ«ä¸æ–‡æœ¬æ•´ç†å·¥å…·") as app:
        gr.Markdown("# ğŸ§ éŸ³é¢‘è¯†åˆ«ä¸æ–‡æœ¬æ•´ç†ç³»ç»Ÿ")
        gr.Markdown("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶æˆ–è¾“å…¥Bç«™è§†é¢‘é“¾æ¥ï¼Œä¸€é”®æå–æ–‡æœ¬å¹¶ç”Ÿæˆå›¾æ–‡ç‰ˆã€‚")
        # é¢„å…ˆåŠ è½½ .env é…ç½®ï¼Œç”¨äºè®¾ç½®å„ Tab é»˜è®¤å€¼ï¼ˆä¾‹å¦‚ TEXT_ONLY_DEFAULTï¼‰
        env_config = load_env_config()

        with gr.Tab("è¾“å…¥Bç«™é“¾æ¥"):
            with gr.Row():
                bilibili_input = gr.Textbox(label="è¯·è¾“å…¥Bç«™è§†é¢‘é“¾æ¥")
            with gr.Row():
                llm_api_dropdown2 = gr.Dropdown(choices=LLM_SERVER_SUPPORTED, value=LLM_SERVER, label="é€‰æ‹©LLMæœåŠ¡")
                temp_slider2 = gr.Slider(0.0, 1.0, step=0.05, value=LLM_TEMPERATURE, label="Temperature")
                token_slider2 = gr.Slider(100, 8000, step=100, value=LLM_MAX_TOKENS, label="Max Tokens")
                # æ–°å¢ï¼šä»…è¿”å›çº¯æ–‡æœ¬(JSON)å¼€å…³
                text_only2 = gr.Checkbox(label="ä»…è¿”å›æ–‡æœ¬(JSON)",
                                         value=env_config.get("TEXT_ONLY_DEFAULT", "false").lower() == "true")
            bilibili_button = gr.Button("ä¸‹è½½å¹¶å¤„ç†")
            bilibili_output = gr.Textbox(label="è¾“å‡ºç›®å½•", interactive=False)
            bilibili_time = gr.Textbox(label="ä¸‹è½½+è¯†åˆ«+æ¶¦è‰²ç”¨æ—¶ï¼ˆç§’ï¼‰", interactive=False)

            with gr.Row():
                download_zip2 = gr.File(label="ä¸‹è½½æ‰“åŒ…ç»“æœï¼ˆZIPï¼‰", interactive=False)

            bilibili_button.click(
                fn=bilibili_video_download_process,
                inputs=[bilibili_input, llm_api_dropdown2, temp_slider2, token_slider2, text_only2],
                outputs=[bilibili_output, bilibili_time, bilibili_time, download_zip2]
            )

        with gr.Tab("æ‰¹é‡å¤„ç†Bç«™é“¾æ¥"):
            with gr.Row():
                url_input = gr.Textbox(label="è¯·è¾“å…¥Bç«™è§†é¢‘é“¾æ¥ï¼Œæ¯ä¸ªURLæ¢è¡Œåˆ†éš”")
            with gr.Row():
                llm_api_dropdown3 = gr.Dropdown(choices=LLM_SERVER_SUPPORTED, value=LLM_SERVER, label="é€‰æ‹©LLMæœåŠ¡")
                temp_slider3 = gr.Slider(0.0, 1.0, step=0.05, value=LLM_TEMPERATURE, label="Temperature")
                token_slider3 = gr.Slider(100, 8000, step=100, value=LLM_MAX_TOKENS, label="Max Tokens")
                # æ–°å¢ï¼šä»…è¿”å›çº¯æ–‡æœ¬(JSON)å¼€å…³
                text_only3 = gr.Checkbox(label="ä»…è¿”å›æ–‡æœ¬(JSON)",
                                         value=env_config.get("TEXT_ONLY_DEFAULT", "false").lower() == "true")
            batch_button = gr.Button("æ‰¹é‡ä¸‹è½½å¹¶å¤„ç†")
            batch_output = gr.Textbox(label="è¾“å‡ºæ–‡ä»¶", interactive=False)
            batch_time = gr.Textbox(label="æ€»ä¸‹è½½+è¯†åˆ«+æ¶¦è‰²ç”¨æ—¶ï¼ˆç§’ï¼‰", interactive=False)
            with gr.Row():
                download_zip_batch = gr.File(label="ä¸‹è½½æ‰“åŒ…ç»“æœï¼ˆZIPï¼‰", interactive=False)

            batch_button.click(
                fn=process_multiple_urls,
                inputs=[url_input, llm_api_dropdown3, temp_slider3, token_slider3, text_only3],
                outputs=[batch_output, batch_time, batch_time, download_zip_batch]
            )

        with gr.Tab("ä¸Šä¼ æœ¬åœ°éŸ³é¢‘æ–‡ä»¶"):
            with gr.Row():
                audio_input = gr.File(label="é€‰æ‹©æœ¬åœ°éŸ³é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒmp3/wavæ ¼å¼ï¼‰")
            with gr.Row():
                llm_api_dropdown1 = gr.Dropdown(choices=LLM_SERVER_SUPPORTED, value=LLM_SERVER, label="é€‰æ‹©LLMæœåŠ¡")
                temp_slider1 = gr.Slider(0.0, 1.0, step=0.05, value=LLM_TEMPERATURE, label="Temperature")
                token_slider1 = gr.Slider(100, 8000, step=100, value=LLM_MAX_TOKENS, label="Max Tokens")
                # æ–°å¢ï¼šä»…è¿”å›çº¯æ–‡æœ¬(JSON)å¼€å…³
                text_only1 = gr.Checkbox(label="ä»…è¿”å›æ–‡æœ¬(JSON)",
                                         value=env_config.get("TEXT_ONLY_DEFAULT", "false").lower() == "true")
            upload_button = gr.Button("å¼€å§‹å¤„ç†")
            upload_output = gr.Textbox(label="è¾“å‡ºç›®å½•", interactive=False)
            upload_time = gr.Textbox(label="è¯†åˆ«+æ¶¦è‰²ç”¨æ—¶ï¼ˆç§’ï¼‰", interactive=False)

            with gr.Row():
                download_zip1 = gr.File(label="ä¸‹è½½æ‰“åŒ…ç»“æœï¼ˆZIPï¼‰", interactive=False)

            upload_button.click(
                fn=upload_audio,
                inputs=[audio_input, llm_api_dropdown1, temp_slider1, token_slider1, text_only1],
                outputs=[upload_output, upload_time, upload_time, download_zip1]
            )

        with gr.Tab("ä¸Šä¼ æœ¬åœ°è§†é¢‘æ–‡ä»¶"):
            with gr.Row():
                video_input2 = gr.File(label="é€‰æ‹©æœ¬åœ°è§†é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒmp4æ ¼å¼ï¼‰")
            video_button = gr.Button("æå–éŸ³é¢‘å¹¶å¤„ç†")
            video_output = gr.Textbox(label="è¾“å‡ºç›®å½•", interactive=False)
            video_time = gr.Textbox(label="æå–+è¯†åˆ«+æ¶¦è‰²ç”¨æ—¶ï¼ˆç§’ï¼‰", interactive=False)

            with gr.Row():
                download_zip_video = gr.File(label="ä¸‹è½½æ‰“åŒ…ç»“æœï¼ˆZIPï¼‰", interactive=False)

            video_button.click(
                fn=lambda vf, api, temp, tokens, text_only: upload_audio(
                    extract_audio_from_video(vf), api, temp, tokens, text_only
                ) if vf else ("è¯·ä¸Šä¼ ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ã€‚", None, None, None),
                inputs=[video_input2, llm_api_dropdown1, temp_slider1, token_slider1, text_only1],
                outputs=[video_output, video_time, video_time, download_zip_video]
            )

        with gr.Tab("è‡ªåŠ¨æ·»åŠ å­—å¹•"):
            video_input = gr.File(label="é€‰æ‹©è§†é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒmp4æ ¼å¼ï¼‰")
            subtitle_button = gr.Button("æ·»åŠ å­—å¹•å¹¶ä¸‹è½½")
            dot_srt_file = gr.File(label="ä¸‹è½½è¾“å‡ºå­—å¹•æ–‡ä»¶ï¼ˆ.srtï¼‰", interactive=False)
            subtitle_download = gr.File(label="ä¸‹è½½å¸¦å­—å¹•çš„è§†é¢‘", interactive=False)

            subtitle_button.click(
                fn=process_subtitles,
                inputs=video_input,
                outputs=[dot_srt_file, subtitle_download]
            )

        with gr.Tab("ç³»ç»Ÿé…ç½®"):
            gr.Markdown("## é…ç½®ç®¡ç†")
            gr.Markdown("åœ¨è¿™é‡Œä¿®æ”¹ç³»ç»Ÿé…ç½®ï¼Œä¿å­˜åéœ€è¦é‡å¯åº”ç”¨æ‰èƒ½ç”Ÿæ•ˆã€‚")

            # åŠ è½½å½“å‰é…ç½®
            # env_config = load_env_config()

            with gr.Accordion("API Keys", open=True):
                deepseek_key = gr.Textbox(
                    label="DeepSeek API Key",
                    value=env_config.get("DEEPSEEK_API_KEY", ""),
                    type="password"
                )
                gemini_key = gr.Textbox(
                    label="Gemini API Key",
                    value=env_config.get("GEMINI_API_KEY", ""),
                    type="password"
                )
                dashscope_key = gr.Textbox(
                    label="DashScope API Key (é€šä¹‰åƒé—®)",
                    value=env_config.get("DASHSCOPE_API_KEY", ""),
                    type="password"
                )
                cerebras_key = gr.Textbox(
                    label="Cerebras API Key",
                    value=env_config.get("CEREBRAS_API_KEY", ""),
                    type="password"
                )

            with gr.Accordion("ç›®å½•é…ç½®", open=False):
                output_dir = gr.Textbox(
                    label="è¾“å‡ºç›®å½•",
                    value=env_config.get("OUTPUT_DIR", "./out")
                )
                download_dir = gr.Textbox(
                    label="ä¸‹è½½ç›®å½•",
                    value=env_config.get("DOWNLOAD_DIR", "./download")
                )
                temp_dir = gr.Textbox(
                    label="ä¸´æ—¶ç›®å½•",
                    value=env_config.get("TEMP_DIR", "./temp")
                )
                model_dir = gr.Textbox(
                    label="æ¨¡å‹ç›®å½•ï¼ˆç•™ç©ºä½¿ç”¨é»˜è®¤ï¼‰",
                    value=env_config.get("MODEL_DIR", "")
                )
                log_dir = gr.Textbox(
                    label="æ—¥å¿—ç›®å½•",
                    value=env_config.get("LOG_DIR", "./logs")
                )

            with gr.Accordion("æ—¥å¿—é…ç½®", open=False):
                log_level = gr.Dropdown(
                    choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
                    label="æ—¥å¿—çº§åˆ«",
                    value=env_config.get("LOG_LEVEL", "INFO")
                )
                log_file = gr.Textbox(
                    label="æ—¥å¿—æ–‡ä»¶è·¯å¾„",
                    value=env_config.get("LOG_FILE", "./logs/AutoVoiceCollation.log")
                )
                log_console = gr.Checkbox(
                    label="è¾“å‡ºåˆ°æ§åˆ¶å°",
                    value=env_config.get("LOG_CONSOLE_OUTPUT", "true").lower() == "true"
                )
                log_colored = gr.Checkbox(
                    label="å½©è‰²è¾“å‡º",
                    value=env_config.get("LOG_COLORED_OUTPUT", "true").lower() == "true"
                )
                third_party_log_level = gr.Dropdown(
                    choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
                    label="ç¬¬ä¸‰æ–¹åº“æ—¥å¿—çº§åˆ«",
                    value=env_config.get("THIRD_PARTY_LOG_LEVEL", "ERROR")
                )

            with gr.Accordion("ASR å’Œè¾“å‡ºé…ç½®", open=False):
                asr_model = gr.Dropdown(
                    choices=["paraformer", "sense_voice"],
                    label="ASR æ¨¡å‹",
                    value=env_config.get("ASR_MODEL", "paraformer")
                )
                output_style = gr.Dropdown(
                    choices=["pdf_with_img", "img_only", "text_only", "pdf_only"],
                    label="è¾“å‡ºæ ·å¼",
                    value=env_config.get("OUTPUT_STYLE", "pdf_only")
                )
                zip_enabled = gr.Checkbox(
                    label="å¯ç”¨ ZIP å‹ç¼©è¾“å‡º",
                    value=env_config.get("ZIP_OUTPUT_ENABLED", "false").lower() == "true"
                )
                # æ–°å¢ï¼šè®°ä½ Web UI ä¸­ text_only çš„é»˜è®¤å€¼
                text_only_default = gr.Checkbox(
                    label="é»˜è®¤ä»…è¿”å›æ–‡æœ¬(JSON)",
                    value=env_config.get("TEXT_ONLY_DEFAULT", "false").lower() == "true"
                )

            with gr.Accordion("LLM é…ç½®", open=False):
                llm_server = gr.Dropdown(
                    choices=LLM_SERVER_SUPPORTED,
                    label="LLM æœåŠ¡",
                    value=env_config.get("LLM_SERVER", "Cerebras:Qwen-3-235B-Instruct")
                )
                llm_temp = gr.Slider(
                    minimum=0.0,
                    maximum=2.0,
                    step=0.05,
                    label="Temperature",
                    value=float(env_config.get("LLM_TEMPERATURE", "0.1"))
                )
                llm_tokens = gr.Slider(
                    minimum=100,
                    maximum=8000,
                    step=100,
                    label="Max Tokens",
                    value=int(env_config.get("LLM_MAX_TOKENS", "6000"))
                )
                llm_top_p = gr.Slider(
                    minimum=0.0,
                    maximum=1.0,
                    step=0.01,
                    label="Top P",
                    value=float(env_config.get("LLM_TOP_P", "0.95"))
                )
                llm_top_k = gr.Slider(
                    minimum=0,
                    maximum=100,
                    step=1,
                    label="Top K",
                    value=int(env_config.get("LLM_TOP_K", "64"))
                )
                split_limit = gr.Slider(
                    minimum=100,
                    maximum=5000,
                    step=100,
                    label="æ–‡æœ¬åˆ†æ®µé•¿åº¦",
                    value=int(env_config.get("SPLIT_LIMIT", "1000"))
                )
                async_flag = gr.Checkbox(
                    label="å¯ç”¨å¼‚æ­¥å¤„ç†",
                    value=env_config.get("ASYNC_FLAG", "true").lower() == "true"
                )

            with gr.Accordion("æ‘˜è¦ç”Ÿæˆé…ç½®", open=False):
                summary_server = gr.Dropdown(
                    choices=LLM_SERVER_SUPPORTED,
                    label="æ‘˜è¦ LLM æœåŠ¡",
                    value=env_config.get("SUMMARY_LLM_SERVER", "Cerebras:Qwen-3-235B-Thinking")
                )
                summary_temp = gr.Slider(
                    minimum=0.0,
                    maximum=2.0,
                    step=0.05,
                    label="æ‘˜è¦ Temperature",
                    value=float(env_config.get("SUMMARY_LLM_TEMPERATURE", "1.0"))
                )
                summary_tokens = gr.Slider(
                    minimum=100,
                    maximum=16000,
                    step=100,
                    label="æ‘˜è¦ Max Tokens",
                    value=int(env_config.get("SUMMARY_LLM_MAX_TOKENS", "8192"))
                )

            with gr.Accordion("åŠŸèƒ½å¼€å…³", open=False):
                disable_polish = gr.Checkbox(
                    label="ç¦ç”¨ LLM æ¶¦è‰²",
                    value=env_config.get("DISABLE_LLM_POLISH", "false").lower() == "true"
                )
                disable_summary = gr.Checkbox(
                    label="ç¦ç”¨ LLM æ‘˜è¦",
                    value=env_config.get("DISABLE_LLM_SUMMARY", "false").lower() == "true"
                )
                local_llm = gr.Checkbox(
                    label="å¯ç”¨æœ¬åœ° LLM",
                    value=env_config.get("LOCAL_LLM_ENABLED", "false").lower() == "true"
                )
                debug_flag = gr.Checkbox(
                    label="è°ƒè¯•æ¨¡å¼",
                    value=env_config.get("DEBUG_FLAG", "false").lower() == "true"
                )

            with gr.Accordion("Web æœåŠ¡å™¨é…ç½®", open=False):
                web_port = gr.Number(
                    label="Web æœåŠ¡å™¨ç«¯å£ï¼ˆç•™ç©ºä¸ºè‡ªåŠ¨ï¼‰",
                    value=int(env_config.get("WEB_SERVER_PORT", "0")) if env_config.get("WEB_SERVER_PORT",
                                                                                        "") else None,
                    precision=0
                )

            # ä¿å­˜æŒ‰é’®å’ŒçŠ¶æ€æ˜¾ç¤º
            save_button = gr.Button("ä¿å­˜é…ç½®", variant="primary", size="lg")
            save_status = gr.Textbox(label="ä¿å­˜çŠ¶æ€", interactive=False)

            # ç»‘å®šä¿å­˜äº‹ä»¶
            save_button.click(
                fn=update_config,
                inputs=[
                    deepseek_key, gemini_key, dashscope_key, cerebras_key,
                    output_dir, download_dir, temp_dir, model_dir, log_dir,
                    log_level, log_file, log_console, log_colored, third_party_log_level,
                    asr_model, output_style, zip_enabled, text_only_default,
                    llm_server, llm_temp, llm_tokens, llm_top_p, llm_top_k, split_limit, async_flag,
                    summary_server, summary_temp, summary_tokens,
                    disable_polish, disable_summary, local_llm, debug_flag,
                    web_port
                ],
                outputs=[save_status]
            )

    return app


def launch_ui(server_name: str = "0.0.0.0", server_port: int | None = None, share: bool = False):
    app = create_app()
    # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå…¶æ¬¡ä½¿ç”¨é…ç½®ä¸­çš„ WEB_SERVER_PORTï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå¦åˆ™è®© gradio è‡ªåŠ¨é€‰æ‹©
    port = server_port or (
        int(WEB_SERVER_PORT) if (globals().get('WEB_SERVER_PORT') and str(WEB_SERVER_PORT).strip()) else None)
    should_launch_browser = '--from-electron' not in sys.argv
    app.launch(server_name=server_name, server_port=port, share=share, inbrowser=should_launch_browser)


if __name__ == "__main__":
    launch_ui()
