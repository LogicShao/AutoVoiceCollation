# AutoVoiceCollation - å¼€å‘è€…æ–‡æ¡£ï¼ˆLLM äº¤äº’ï¼‰

> âœ… é¡¹ç›®ç‰ˆæœ¬ï¼šv2.0 | LLM äº¤äº’æ¨¡å—åŸºäº OpenAI å…¼å®¹æ¥å£è®¾è®¡ï¼Œæ”¯æŒå¤šæä¾›å•†é›†æˆ

---

## é¡¹ç›®æ¦‚è¿°

AutoVoiceCollation æ˜¯ä¸€ä¸ªåŸºäº Python çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ä¸æ™ºèƒ½æ–‡æœ¬å¤„ç†ç³»ç»Ÿï¼Œç»“åˆ FunASR ä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æŠ€æœ¯ï¼Œå®ç°ä»éŸ³è§†é¢‘åˆ°ç²¾ç¾æ–‡æ¡£çš„å…¨æµç¨‹è‡ªåŠ¨åŒ–ã€‚

### ğŸ› ï¸ æ ¸å¿ƒæŠ€æœ¯æ ˆ
- **ASR**ï¼šFunASRï¼ˆParaformer / SenseVoice æ¨¡å‹ï¼‰
- **æ·±åº¦å­¦ä¹ **ï¼šPyTorch, Transformers
- **LLM é›†æˆ**ï¼šOpenAI API å…¼å®¹æ¥å£ï¼ˆDeepSeek, Gemini, Qwen, Cerebras, æœ¬åœ°æ¨¡å‹ï¼‰
- **æ–‡æ¡£å¤„ç†**ï¼šReportLabï¼ˆPDF ç”Ÿæˆï¼‰ã€Pillowï¼ˆå›¾ç‰‡å¤„ç†ï¼‰
- **è§†é¢‘å¤„ç†**ï¼šyt-dlpï¼ˆè§†é¢‘ä¸‹è½½ï¼‰ã€FFmpegï¼ˆéŸ³è§†é¢‘å¤„ç†ï¼‰
- **é…ç½®ç®¡ç†**ï¼špython-dotenv
- **å¼‚æ­¥å¤„ç†**ï¼šasyncioï¼ˆæ‰¹é‡å¼‚æ­¥æ–‡æœ¬æ¶¦è‰²ï¼‰

---

## é¡¹ç›®æ¶æ„

### 1. æ¨¡å—ç»“æ„ï¼ˆæ¨¡å—åŒ–æ¶æ„ v2.0ï¼‰

```bash
AutoVoiceCollation/
â”œâ”€â”€ main.py                        # CLI å…¥å£
â”œâ”€â”€ api.py                         # Web/API æœåŠ¡
â”‚
â”œâ”€â”€ src/                           # æ ¸å¿ƒä»£ç ç›®å½•ï¼ˆæ¨¡å—åŒ–æ¶æ„ï¼‰
â”‚   â”œâ”€â”€ api/                       # API å±‚
â”‚   â”‚   â”œâ”€â”€ inference_queue.py     # å¼‚æ­¥æ¨ç†é˜Ÿåˆ—ï¼ˆè§£å†³ FastAPI é˜»å¡ï¼‰
â”‚   â”‚   â”œâ”€â”€ middleware/            # ä¸­é—´ä»¶ï¼ˆé”™è¯¯å¤„ç†ç­‰ï¼‰
â”‚   â”‚   â””â”€â”€ schemas/               # Pydantic æ•°æ®æ¨¡å‹
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                      # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â”‚   â”œâ”€â”€ exceptions/            # å¼‚å¸¸å®šä¹‰ï¼ˆASR/LLM/ä¸‹è½½/æ–‡ä»¶/ä»»åŠ¡ï¼‰
â”‚   â”‚   â”œâ”€â”€ export/                # å¯¼å‡ºåŠŸèƒ½ï¼ˆPDF/å›¾ç‰‡/å­—å¹•ï¼‰
â”‚   â”‚   â”œâ”€â”€ history/               # å¤„ç†å†å²ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ models/                # æ•°æ®æ¨¡å‹
â”‚   â”‚   â””â”€â”€ processors/            # å¤„ç†å™¨ï¼ˆéŸ³é¢‘/è§†é¢‘/å­—å¹•ï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                  # å¤–éƒ¨æœåŠ¡é›†æˆ
â”‚   â”‚   â”œâ”€â”€ asr/                   # ASR æœåŠ¡ï¼ˆParaformer/SenseVoiceï¼‰
â”‚   â”‚   â”œâ”€â”€ download/              # ä¸‹è½½æœåŠ¡ï¼ˆBç«™è§†é¢‘ä¸‹è½½ï¼‰
â”‚   â”‚   â”œâ”€â”€ llm/                   # LLM æœåŠ¡ï¼ˆå¤šæä¾›å•†æ”¯æŒï¼‰
â”‚   â”‚   â””â”€â”€ subtitle/              # å­—å¹•æœåŠ¡
â”‚   â”‚
â”‚   â”œâ”€â”€ text_arrangement/          # æ–‡æœ¬å¤„ç†
â”‚   â”‚   â”œâ”€â”€ polish_by_llm.py       # æ–‡æœ¬æ¶¦è‰²
â”‚   â”‚   â”œâ”€â”€ query_llm.py           # LLM æ¥å£
â”‚   â”‚   â”œâ”€â”€ split_text.py          # æ–‡æœ¬åˆ†æ®µ
â”‚   â”‚   â”œâ”€â”€ summary_by_llm.py      # æ‘˜è¦ç”Ÿæˆ
â”‚   â”‚   â””â”€â”€ text_exporter.py       # å¯¼å‡ºå·¥å…·
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                     # å·¥å…·ç±»
â”‚   â”‚   â”œâ”€â”€ config/                # é…ç½®ç®¡ç†ï¼ˆåŸºäº Pydantic v2ï¼‰
â”‚   â”‚   â”œâ”€â”€ device/                # è®¾å¤‡ç®¡ç†ï¼ˆCPU/GPU/ONNXï¼‰
â”‚   â”‚   â”œâ”€â”€ helpers/               # è¾…åŠ©å·¥å…·ï¼ˆä»»åŠ¡ç®¡ç†å™¨ç­‰ï¼‰
â”‚   â”‚   â””â”€â”€ logging/               # æ—¥å¿—ç³»ç»Ÿ
â”‚   â”‚
â”‚   â””â”€â”€ SenseVoiceSmall/           # SenseVoice æ¨¡å‹å®ç°
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ model.py               # æ¨¡å‹å®šä¹‰
â”‚       â”œâ”€â”€ ctc_alignment.py       # CTC å¯¹é½
â”‚       â””â”€â”€ export_meta.py         # å…ƒæ•°æ®å¯¼å‡º
â”‚
â”œâ”€â”€ tests/                         # æµ‹è¯•ç›®å½•
â”‚   â”œâ”€â”€ conftest.py                # pytest é…ç½®
â”‚   â”œâ”€â”€ test_async_queue.py        # å¼‚æ­¥æ¨ç†é˜Ÿåˆ—æµ‹è¯•
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ .env.example                   # ç¯å¢ƒå˜é‡é…ç½®ç¤ºä¾‹
â”œâ”€â”€ requirements.txt               # Python ä¾èµ–
â””â”€â”€ README.md                      # ç”¨æˆ·æ–‡æ¡£
```

### 2. æ ¸å¿ƒå¤„ç†æµç¨‹

```mermaid
graph TD
    A[ç”¨æˆ·è¾“å…¥ (CLI/Web/API)] --> B[ä¸‹è½½/ä¸Šä¼ é˜¶æ®µ]
    B --> C{Bç«™è§†é¢‘}
    B --> D{æœ¬åœ°è§†é¢‘}
    B --> E{æœ¬åœ°éŸ³é¢‘}
    
    C --> F[bilibili_downloader.download_bilibili_audio()]
    D --> G[bilibili_downloader.extract_audio_from_video()]
    E --> H[ç›´æ¥ä½¿ç”¨]
    
    F --> I[ASR è¯†åˆ«é˜¶æ®µ]
    G --> I
    H --> I
    
    I --> J[extract_audio_text.extract_audio_text()]
    J --> K{åŠ è½½æ¨¡å‹: Paraformer/SenseVoice}
    K --> L[è®¾å¤‡é€‰æ‹©: GPU/CPU/ONNX]
    L --> M[éŸ³é¢‘è½¬æ–‡æœ¬]
    
    M --> N[æ–‡æœ¬å¤„ç†é˜¶æ®µ]
    N --> O[split_text() â†’ æ–‡æœ¬åˆ†æ®µ]
    N --> P[polish_by_llm() â†’ LLM æ¶¦è‰²]
    N --> Q[summarize_text() â†’ LLM æ‘˜è¦ç”Ÿæˆ]
    
    P --> R{åŒæ­¥/å¼‚æ­¥æ¨¡å¼}
    R --> S[é¡ºåºå¤„ç†]
    R --> T[å¹¶å‘å¤„ç†]
    
    O --> U[åˆå¹¶ç­–ç•¥]
    Q --> U
    U --> V[è¾“å‡ºé˜¶æ®µ]
    
    V --> W[text_exporter.text_to_img_or_pdf()]
    V --> X[subtitle_generator (å¯é€‰)]
    V --> Y[ZIP å‹ç¼© (å¯é€‰)]
```

### 3. é…ç½®ç³»ç»Ÿè®¾è®¡ï¼ˆåŸºäº Pydantic v2ï¼‰

#### `src/utils/config/` æ¶æ„

- **ç±»å‹å®‰å…¨é…ç½®**ï¼šä½¿ç”¨ Pydantic v2 è¿›è¡Œé…ç½®éªŒè¯å’Œç±»å‹è½¬æ¢
- **ç¯å¢ƒå˜é‡è‡ªåŠ¨åŠ è½½**ï¼šæ”¯æŒåµŒå¥—é…ç½®å’Œè‡ªåŠ¨ç¯å¢ƒå˜é‡æ˜ å°„
- **é…ç½®çƒ­é‡è½½**ï¼šæ”¯æŒè¿è¡Œæ—¶é…ç½®æ›´æ–°
- **é…ç½®åˆ†ç»„**ï¼š
  - `AppConfig`ï¼šä¸»é…ç½®ç±»ï¼Œèšåˆæ‰€æœ‰å­é…ç½®
  - `LLMConfig`ï¼šLLM ç›¸å…³é…ç½®ï¼ˆAPI Keysã€æ¨¡å‹é€‰æ‹©ã€å‚æ•°ï¼‰
  - `ASRConfig`ï¼šASR ç›¸å…³é…ç½®ï¼ˆæ¨¡å‹é€‰æ‹©ã€æ‰¹å¤„ç†å¤§å°ã€è®¾å¤‡ï¼‰
  - `PathConfig`ï¼šè·¯å¾„é…ç½®ï¼ˆè¾“å‡ºç›®å½•ã€ç¼“å­˜ç›®å½•ã€æ¨¡å‹ç›®å½•ï¼‰
  - `LoggingConfig`ï¼šæ—¥å¿—é…ç½®ï¼ˆçº§åˆ«ã€æ ¼å¼ã€è¾“å‡ºæ–‡ä»¶ï¼‰
- **å…³é”®é…ç½®é¡¹**ï¼š
  - `ASR_MODEL`ï¼š`paraformer`ï¼ˆé«˜ç²¾åº¦ï¼‰æˆ– `sense_voice`ï¼ˆå¿«é€Ÿ/å¤šè¯­è¨€ï¼‰
  - `LLM_SERVER`ï¼šå½“å‰ä½¿ç”¨çš„ LLM æœåŠ¡ï¼ˆæ”¯æŒï¼š`deepseek-chat`, `gemini-2.0-flash`, `qwen3-plus`, `Cerebras:*`, `local:*`ï¼‰
  - `ASYNC_FLAG`ï¼šå¯ç”¨å¼‚æ­¥ LLM æ¶¦è‰²ï¼ˆé»˜è®¤ `true`ï¼‰
  - `DEVICE`ï¼š`auto`ï¼ˆè‡ªåŠ¨æ£€æµ‹ GPUï¼‰ã€`cpu`ã€`cuda:0` ç­‰
  - `USE_ONNX`ï¼šå¯ç”¨ ONNX Runtime æ¨ç†åŠ é€Ÿ
  - `DISABLE_LLM_POLISH` / `DISABLE_LLM_SUMMARY`ï¼šåŠŸèƒ½å¼€å…³

#### ä½¿ç”¨æ–¹å¼
```python
from src.utils.config import get_config

# è·å–å…¨å±€é…ç½®
config = get_config()

# è®¿é—®é…ç½®é¡¹
llm_server = config.llm.server  # å¦‚: "deepseek-chat"
asr_model = config.asr.model    # å¦‚: "paraformer"
device = config.device          # å¦‚: "auto"

# æ£€æŸ¥åŠŸèƒ½å¼€å…³
if not config.llm.disable_polish:
    # æ‰§è¡Œ LLM æ¶¦è‰²
    pass
```

#### æ”¯æŒçš„ LLM æœåŠ¡

```python
LLM_SERVER_SUPPORTED = [
    "qwen3-plus",              # é˜¿é‡Œé€šä¹‰åƒé—® Plus
    "qwen3-max",               # é˜¿é‡Œé€šä¹‰åƒé—® Max
    "deepseek-chat",           # DeepSeek å¯¹è¯æ¨¡å‹
    "deepseek-reasoner",       # DeepSeek æ¨ç†æ¨¡å‹
    "Cerebras:Qwen-3-32B",     # Cerebras åŠ é€Ÿ Qwen 32B
    "Cerebras:Qwen-3-235B-Instruct",  # Cerebras Qwen 235B
    "Cerebras:Qwen-3-235B-Thinking",  # Cerebras Qwen æ€è€ƒæ¨¡å¼
    "gemini-2.0-flash",        # Google Gemini 2.0 Flash
    "local:Qwen/Qwen2.5-1.5B-Instruct",  # æœ¬åœ°æ¨¡å‹
]
```

---

## å…³é”®æ¨¡å—è¯¦è§£

### 1. `src/services/download/bilibili_downloader.py`

- **åŠŸèƒ½**ï¼šBç«™è§†é¢‘ä¸‹è½½ä¸éŸ³é¢‘æå–
- **æ ¸å¿ƒç±»**ï¼š
  - `BiliVideoFile`ï¼šè§†é¢‘å…ƒæ•°æ®å®¹å™¨
    - å±æ€§ï¼š`title`, `path`, `bvid`, `url`, `duration`, `owner`
    - æ–¹æ³•ï¼š`save_in_json()`, `save_in_text()`
- **æ ¸å¿ƒå‡½æ•°**ï¼š
  - `download_bilibili_audio(url, output_format='mp3', output_dir=DOWNLOAD_DIR)`
    - ä½¿ç”¨ `yt-dlp` ä¸‹è½½éŸ³é¢‘
    - æ”¯æŒæ ¼å¼ï¼šmp3, wav, flac, m4a
    - è¿”å› `BiliVideoFile` å¯¹è±¡
  - `extract_audio_from_video(video_path)`
    - ä½¿ç”¨ `FFmpeg` æå–éŸ³é¢‘
    - è¾“å‡ºæ ¼å¼ï¼šmp3
    - è¿”å›éŸ³é¢‘è·¯å¾„
- **ä¾èµ–**ï¼šyt-dlp, FFmpeg

### 2. `src/services/asr/`ï¼ˆASR æœåŠ¡æŠ½è±¡å±‚ï¼‰

- **åŠŸèƒ½**ï¼šç»Ÿä¸€çš„ ASR æœåŠ¡æ¥å£ï¼Œæ”¯æŒå¤šç§æ¨¡å‹
- **æ”¯æŒæ¨¡å‹**ï¼š
  - `paraformer`ï¼šé«˜å‡†ç¡®åº¦ï¼Œé€‚åˆä¸­æ–‡
  - `sense_voice`ï¼šå¤šè¯­è¨€æ”¯æŒï¼Œé€Ÿåº¦å¿«
- **æ ¸å¿ƒç»„ä»¶**ï¼š
  - `transcriber.py`ï¼šASR è½¬å½•å™¨åŸºç±»å’Œå…·ä½“å®ç°
  - `preprocess.py`ï¼šéŸ³é¢‘é¢„å¤„ç†å·¥å…·
- **è®¾å¤‡ç®¡ç†**ï¼šé€šè¿‡ `src/utils/device/` è‡ªåŠ¨æ£€æµ‹ GPU/CPU
- **ONNX æ”¯æŒ**ï¼šå¯åœ¨ `.env` ä¸­é…ç½® `USE_ONNX=true`
- **æ€§èƒ½ä¼˜åŒ–**ï¼š
  - `batch_size_s`ï¼šæ‰¹å¤„ç†å¤§å°ï¼ˆç§’ï¼‰ï¼Œéœ€æ ¹æ®æ˜¾å­˜è°ƒæ•´
  - ONNX æ¨ç†ï¼šå¯ç”¨åå¯åŠ é€Ÿæ¨ç†

### 3. `src/services/llm/`ï¼ˆLLM æœåŠ¡æŠ½è±¡å±‚ï¼‰

- **åŠŸèƒ½**ï¼šç»Ÿä¸€çš„ LLM æœåŠ¡æ¥å£ï¼Œæ”¯æŒå¤šæä¾›å•†
- **è®¾è®¡æ¨¡å¼**ï¼šå·¥å‚æ¨¡å¼ + ç­–ç•¥æ¨¡å¼
- **æ ¸å¿ƒç»„ä»¶**ï¼š
  - `factory.py`ï¼šLLM å·¥å‚ï¼Œæ ¹æ®é…ç½®åˆ›å»ºå¯¹åº”çš„ LLM æœåŠ¡å®ä¾‹
  - `base.py`ï¼šæŠ½è±¡åŸºç±»ï¼Œå®šä¹‰ç»Ÿä¸€çš„ LLM æ¥å£
  - å…·ä½“å®ç°ï¼š`deepseek.py`, `gemini.py`, `qwen.py`, `cerebras.py`, `local.py`
- **æ”¯æŒçš„æœåŠ¡**ï¼š
  - âœ… **DeepSeek**ï¼š`deepseek-chat`, `deepseek-reasoner`
  - âœ… **Gemini**ï¼š`gemini-2.0-flash`
  - âœ… **Qwen**ï¼š`qwen3-plus`, `qwen3-max`
  - âœ… **Cerebras**ï¼š`Cerebras:Qwen-3-32B`, `Cerebras:Qwen-3-235B-Instruct`
  - âœ… **æœ¬åœ°æ¨¡å‹**ï¼š`local:Qwen/Qwen2.5-1.5B-Instruct`
- **å¼‚æ­¥å¤„ç†**ï¼š
  - `polish_by_llm.py` ä½¿ç”¨ `asyncio.gather()` å¹¶å‘è°ƒç”¨å¤šä¸ª LLM API
  - é€Ÿç‡é™åˆ¶ï¼š`RateLimiter` ç±»ï¼ˆé»˜è®¤ 10 req/minï¼‰
  - é‡è¯•æœºåˆ¶ï¼šæœ€å¤š 3 æ¬¡é‡è¯•ï¼ŒæŒ‡æ•°é€€é¿ 30 ç§’

### 4. `src/text_arrangement/polish_by_llm.py`

- **åŠŸèƒ½**ï¼šä½¿ç”¨ LLM æ¶¦è‰²æ–‡æœ¬
- **æ ¸å¿ƒç‰¹æ€§**ï¼š
  - âœ… å¼‚æ­¥æ‰¹å¤„ç†ï¼šä½¿ç”¨ `asyncio` å¹¶å‘å¤„ç†å¤šä¸ªæ–‡æœ¬æ®µ
  - âœ… æ–‡æœ¬åˆ†æ®µï¼šè‡ªåŠ¨åˆ†æ®µä»¥é€‚åº” LLM token é™åˆ¶
  - âœ… åˆå¹¶ç­–ç•¥ï¼šå°†æ¶¦è‰²åçš„æ®µè½åˆå¹¶ä¸ºå®Œæ•´æ–‡æœ¬
  - âœ… ä»»åŠ¡å–æ¶ˆæ”¯æŒï¼šé›†æˆä»»åŠ¡ç®¡ç†å™¨ï¼Œæ”¯æŒå–æ¶ˆæ“ä½œ
- **æ ¸å¿ƒå‡½æ•°**ï¼š
  ```python
  def polish_text(
      audio_text: str,
      api_service: str,
      split_len: int = 6000,
      temperature: float = 0.1,
      max_tokens: int = 4000,
      async_flag: bool = True,
      debug_flag: bool = False,
      task_id: Optional[str] = None  # æ–°å¢ï¼šæ”¯æŒä»»åŠ¡å–æ¶ˆ
  ) -> str:
      """
      æ¶¦è‰²æ–‡æœ¬
      :param async_flag: True = å¼‚æ­¥å¹¶å‘å¤„ç†ï¼ŒFalse = é¡ºåºå¤„ç†
      :param task_id: ä»»åŠ¡ IDï¼Œç”¨äºæ”¯æŒä»»åŠ¡å–æ¶ˆ
      :return: æ¶¦è‰²åçš„å®Œæ•´æ–‡æœ¬
      """
  ```
- **å¼‚æ­¥å¤„ç†æµç¨‹**ï¼š
  ```python
  async def async_polish_text_parts(parts: list, api_service: str, **kwargs):
      tasks = [query_llm_async(part, api_service, **kwargs) for part in parts]
      return await asyncio.gather(*tasks)
  ```

### 5. `text_arrangement/text_exporter.py`

- **åŠŸèƒ½**ï¼šå¯¼å‡ºæ–‡æœ¬ä¸º PDF æˆ–å›¾ç‰‡
- **æ”¯æŒæ ¼å¼**ï¼š
  - `pdf_with_img`ï¼šPDF + PNG å›¾ç‰‡
  - `pdf_only`ï¼šä»… PDF
  - `img_only`ï¼šä»… PNG å›¾ç‰‡
  - `text_only`ï¼šJSON æ–‡ä»¶
  - `markdown`ï¼šMarkdown æ–‡ä»¶
  - `json`ï¼šJSON æ–‡ä»¶
  - `markdown`ï¼šMarkdown æ–‡ä»¶
  - `json`ï¼šJSON æ–‡ä»¶
- **æ ¸å¿ƒå‡½æ•°**ï¼š
  ```python
  def text_to_img_or_pdf(
      text: str,
      title: str,
      output_style: str,
      output_path: str,
      LLM_info: dict,
      ASR_model: str
  ) -> str:
      """
      å¯¼å‡ºæ–‡æœ¬
      :return: è¾“å‡ºæ–‡ä»¶è·¯å¾„
      """
  ```
- **å­—ä½“æ”¯æŒ**ï¼šæ”¯æŒä¸­æ–‡å­—ä½“ï¼ˆéœ€ç³»ç»Ÿå®‰è£…æˆ–æŒ‡å®šè·¯å¾„ï¼‰

### 6. `src/services/subtitle/generator.py`

- **åŠŸèƒ½**ï¼šå­—å¹•ç”Ÿæˆä¸è§†é¢‘ç¡¬ç¼–ç 
- **æ ¸å¿ƒæµç¨‹**ï¼š
  1. ASR æ—¶é—´æˆ³è¯†åˆ«ï¼ˆSenseVoice æˆ– Paraformer çš„æ—¶é—´æˆ³æ¨¡å¼ï¼‰
  2. æ–‡æœ¬æ™ºèƒ½åˆ†æ®µï¼ˆåŸºäºåœé¡¿é˜ˆå€¼ `pause_threshold` å’Œæœ€å¤§å­—ç¬¦æ•°ï¼‰
  3. LLM æ–‡æœ¬åŒ¹é…å’Œä¼˜åŒ–ï¼ˆå°†æ¶¦è‰²åçš„æ–‡æœ¬æ˜ å°„åˆ°æ—¶é—´æˆ³ï¼‰
  4. SRT å­—å¹•ç”Ÿæˆå’Œè§†é¢‘ç¡¬ç¼–ç ï¼ˆé€šè¿‡ FFmpegï¼‰
- **é…ç½®ç±»**ï¼š`SubtitleConfig` - å¯è°ƒèŠ‚åœé¡¿é˜ˆå€¼ã€å­—ç¬¦é™åˆ¶ã€LLM å‚æ•°ç­‰
- **æ ¸å¿ƒå‡½æ•°**ï¼š
  - `generate_subtitle_file()` - ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶
  - `encode_subtitle_to_video()` - å°†å­—å¹•çƒ§å½•åˆ°è§†é¢‘
- **è¿”å›**ï¼šå¸¦å­—å¹•çš„è§†é¢‘æ–‡ä»¶è·¯å¾„

### 7. `src/utils/logging/logger.py`

- **åŠŸèƒ½**ï¼šç»Ÿä¸€çš„æ—¥å¿—ç³»ç»Ÿ
- **ç‰¹æ€§**ï¼š
  - å¤šå¤„ç†å™¨ï¼šæ§åˆ¶å° + æ–‡ä»¶
  - å½©è‰²è¾“å‡ºï¼šä½¿ç”¨ `colorlog`
  - ç¬¬ä¸‰æ–¹åº“æ—¥å¿—æ§åˆ¶ï¼šé™ä½ FunASR/modelscope ç­‰åº“æ—¥å¿—çº§åˆ«
  - è‡ªåŠ¨åˆ›å»ºæ—¥å¿—ç›®å½•
  - ç»“æ„åŒ–æ—¥å¿—è¾“å‡º
- **æ ¸å¿ƒå‡½æ•°**ï¼š
  - `get_logger(name)`ï¼šè·å–å‘½å logger
  - `configure_third_party_loggers(log_level)`ï¼šé…ç½®ç¬¬ä¸‰æ–¹åº“æ—¥å¿—çº§åˆ«
- **å¯¼å…¥æ–¹å¼**ï¼š
  ```python
  from src.utils.logging.logger import get_logger
  logger = get_logger(__name__)
  ```

---

## API æœåŠ¡è®¾è®¡

### FastAPI æ¶æ„ (`api.py`)

#### ä»»åŠ¡ç®¡ç†ç³»ç»Ÿ

```python
tasks = {
    "task_id": {
        "status": "pending/processing/completed/failed",
        "message": "...",
        "result": {...},
        "created_at": "2025-10-29T17:35:00.123456",
        "completed_at": "2025-10-29T17:40:30.789012",
        "url": "https://...",  # Bç«™é“¾æ¥
        "filename": "audio.mp3"  # ä¸Šä¼ æ–‡ä»¶å
    }
}
```

#### æ ¸å¿ƒç«¯ç‚¹

| ç«¯ç‚¹ | æ–¹æ³• | æè¿° |
|------|------|------|
| `/api/v1/process/bilibili` | POST | å¤„ç† Bç«™è§†é¢‘ |
| `/api/v1/process/audio` | POST | å¤„ç†éŸ³é¢‘æ–‡ä»¶ |
| `/api/v1/process/batch` | POST | æ‰¹é‡å¤„ç†å¤šä¸ª Bç«™é“¾æ¥ |
| `/api/v1/task/{task_id}` | GET | æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€ |
| `/api/v1/download/{task_id}` | GET | ä¸‹è½½å¤„ç†ç»“æœï¼ˆZIP/PDFï¼‰ |
| `/api/v1/summarize` | POST | çº¯æ–‡æœ¬æ‘˜è¦æœåŠ¡ï¼ˆåŒæ­¥ï¼‰ |

#### è‡ªåŠ¨ç«¯å£å‘ç°

```python
def find_available_port(start_port: int, max_attempts: int = 50) -> int:
    """è‡ªåŠ¨æŸ¥æ‰¾å¯ç”¨ç«¯å£"""
    for offset in range(max_attempts):
        port = start_port + offset
        if is_port_available(port):
            return port
    raise RuntimeError("No available port found")
```

### Web å‰ç«¯è®¾è®¡ (`frontend/`)

- **æ¡†æ¶**ï¼šåŸç”Ÿ HTML/CSS/JS + Alpine.js + Tailwind CSS
- **å…¥å£**ï¼š`frontend/src/index.html` ç”± FastAPI `/` è·¯ç”±è¿”å›
- **äº¤äº’**ï¼š`frontend/src/js/main.js` è½®è¯¢ä»»åŠ¡ã€å±•ç¤ºç»“æœã€ä¸‹è½½æ–‡ä»¶

---

## å¼€å‘æŒ‡å—

### 1. ç¯å¢ƒæ­å»º

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/LogicShao/AutoVoiceCollation
cd AutoVoiceCollation

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n avc_env python=3.11 -y
conda activate avc_env

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å®‰è£… PyTorch (CUDA ç‰ˆæœ¬)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu129

# é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥ API Keys
```

### 2. æ·»åŠ æ–°çš„ LLM æœåŠ¡

1. åœ¨ `src/utils/config/llm.py` ä¸­æ·»åŠ é…ç½®å­—æ®µï¼š
```python
class LLMConfig(BaseModel):
    # ... ç°æœ‰é…ç½®
    new_llm_api_key: Optional[str] = Field(default=None, env="NEW_LLM_API_KEY")
```

2. åœ¨ `LLM_SERVER_SUPPORTED` åˆ—è¡¨ä¸­æ·»åŠ æœåŠ¡åï¼š
```python
LLM_SERVER_SUPPORTED = [..., "new-llm-service"]
```

3. åœ¨ `src/services/llm/` ä¸­åˆ›å»ºæ–°çš„ LLM æœåŠ¡ç±»ï¼š
```python
# new_llm.py
from .base import BaseLLMService

class NewLLMService(BaseLLMService):
    async def generate(self, prompt: str, **kwargs) -> str:
        # å®ç° API è°ƒç”¨é€»è¾‘
        return response_text
```

4. åœ¨ `factory.py` çš„ `create_llm_service()` ä¸­æ·»åŠ åˆ†æ”¯ï¼š
```python
def create_llm_service(config: Optional[LLMConfig] = None) -> BaseLLMService:
    # ... ç°æœ‰é€»è¾‘
    if server == "new-llm-service":
        return NewLLMService(config)
```

5. åœ¨ `.env.example` ä¸­æ·»åŠ é…ç½®è¯´æ˜

### 3. æ·»åŠ æ–°çš„ ASR æ¨¡å‹

1. åœ¨ `src/services/asr/` ä¸­æ·»åŠ æ–°çš„è½¬å½•å™¨ç±»ï¼š
```python
# new_transcriber.py
from .base import BaseTranscriber

class NewModelTranscriber(BaseTranscriber):
    def __init__(self, config: ASRConfig):
        super().__init__(config)
        # åˆå§‹åŒ–æ–°æ¨¡å‹

    def transcribe(self, audio_path: str) -> str:
        # å®ç°è½¬å½•é€»è¾‘
        return transcribed_text
```

2. åœ¨ ASR å·¥å‚ä¸­æ·»åŠ æ–°æ¨¡å‹æ”¯æŒï¼š
```python
# factory.py
def create_transcriber(config: ASRConfig) -> BaseTranscriber:
    if config.model == "new_model":
        return NewModelTranscriber(config)
```

3. æ›´æ–°é…ç½®æ–‡æ¡£å’Œ `.env.example`

### 4. æµ‹è¯•æµç¨‹

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
pytest tests/test_core_process.py

# æŸ¥çœ‹æµ‹è¯•è¦†ç›–ç‡
pytest --cov=src tests/
```

### 5. ä»£ç è§„èŒƒ

- **å‘½åçº¦å®š**ï¼š
  - å‡½æ•°ï¼š`snake_case`
  - ç±»ï¼š`PascalCase`
  - å¸¸é‡ï¼š`UPPER_CASE`
- **æ–‡æ¡£å­—ç¬¦ä¸²**ï¼šä½¿ç”¨ docstring æè¿°å‡½æ•°åŠŸèƒ½å’Œå‚æ•°
- **ç±»å‹æç¤º**ï¼šå°½å¯èƒ½ä½¿ç”¨ç±»å‹æ³¨è§£
- **é”™è¯¯å¤„ç†**ï¼šä½¿ç”¨ try-except æ•è·å¼‚å¸¸ï¼Œè®°å½•æ—¥å¿—

### 6. æ—¥å¿—æœ€ä½³å®è·µ

```python
from src.utils.logging.logger import get_logger

logger = get_logger(__name__)

# ä¸åŒçº§åˆ«çš„æ—¥å¿—
logger.debug("è°ƒè¯•ä¿¡æ¯")
logger.info("ä¸€èˆ¬ä¿¡æ¯")
logger.warning("è­¦å‘Šä¿¡æ¯")
logger.error("é”™è¯¯ä¿¡æ¯")
logger.critical("ä¸¥é‡é”™è¯¯")

# å¸¦å¼‚å¸¸ä¿¡æ¯çš„æ—¥å¿—
try:
    risky_operation()
except Exception as e:
    logger.error(f"æ“ä½œå¤±è´¥: {e}", exc_info=True)
```

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. GPU å†…å­˜ä¼˜åŒ–
- é™ä½ `batch_size_s`ï¼ˆåœ¨ ASR é…ç½®ä¸­ï¼‰
- ä½¿ç”¨ `SenseVoiceSmall` è€Œé `Paraformer`
- å¯ç”¨ ONNX æ¨ç†ï¼ˆ`USE_ONNX=true`ï¼‰
- ä½¿ç”¨ `src/utils/device/` è‡ªåŠ¨æ£€æµ‹æœ€ä½³è®¾å¤‡

### 2. LLM æ¶¦è‰²åŠ é€Ÿ
- å¯ç”¨å¼‚æ­¥å¤„ç†ï¼š`ASYNC_FLAG=true`
- è°ƒæ•´åˆ†æ®µå¤§å°ï¼š`SPLIT_LIMIT=6000`
- ä½¿ç”¨æ›´å¿«çš„ LLM æœåŠ¡ï¼ˆå¦‚ Cerebrasï¼‰

### 3. æ–‡ä»¶å¤„ç†ä¼˜åŒ–
- å¯ç”¨ ZIP è¾“å‡ºï¼š`ZIP_OUTPUT_ENABLED=true`
- ä½¿ç”¨ `text_only` æ¨¡å¼è·³è¿‡ PDF ç”Ÿæˆ

---

## å¸¸è§é—®é¢˜è§£å†³

### 1. FunASR æ¨¡å‹åŠ è½½å¤±è´¥
- **åŸå› **ï¼šç½‘ç»œé—®é¢˜æˆ–ç¼“å­˜æŸå
- **è§£å†³**ï¼š
```bash
rm -rf ~/.cache/modelscope
export MODELSCOPE_CACHE=./models
# æˆ–åœ¨ .env ä¸­é…ç½® MODEL_DIR=./models
```

### 2. CUDA Out of Memory
- **è§£å†³**ï¼š
```python
# åœ¨ ASR é…ç½®ä¸­é™ä½ batch_size_s
# æˆ–åœ¨ .env ä¸­é…ç½® BATCH_SIZE_S=60
batch_size_s = 60  # ä»é»˜è®¤å€¼é™ä½åˆ° 60 æˆ–æ›´å°
```

### 3. FFmpeg æœªæ‰¾åˆ°
- **è§£å†³**ï¼š
```bash
# Ubuntu/Debian
sudo apt-get install ffmpeg

# Windows
# ä¸‹è½½ FFmpeg å¹¶æ·»åŠ åˆ° PATH
```

### 4. ä¸­æ–‡å­—ä½“ç¼ºå¤±
- **è§£å†³**ï¼š
  - Linuxï¼šå®‰è£… `fonts-wqy-zenhei` æˆ– `fonts-noto-cjk`
  - Windowsï¼šç³»ç»Ÿè‡ªå¸¦å®‹ä½“/å¾®è½¯é›…é»‘
  - åœ¨ `text_exporter.py` ä¸­é…ç½®å­—ä½“è·¯å¾„

---

## æ‰©å±•å¼€å‘

### æ·»åŠ æ–°çš„è¾“å‡ºæ ¼å¼ï¼ˆMarkdown ç¤ºä¾‹ï¼‰

1. åœ¨ `src/utils/config/` ä¸­æ·»åŠ è¾“å‡ºé€‰é¡¹ï¼š
```python
# åœ¨ç›¸åº”çš„é…ç½®ç±»ä¸­æ·»åŠ å­—æ®µ
output_style: str = Field(default="pdf_only", env="OUTPUT_STYLE")
# æ”¯æŒ: pdf_with_img, pdf_only, img_only, text_only, markdown, json
```

2. åœ¨ `text_exporter.py` ä¸­å®ç°å¯¼å‡ºå‡½æ•°ï¼š
```python
def text_to_markdown(text, title, output_path):
    md_content = f"# {title}\n\n{text}"
    md_file = os.path.join(output_path, f"{title}.md")
    with open(md_file, "w", encoding="utf-8") as f:
        f.write(md_content)
    return md_file
```

3. åœ¨ `text_to_img_or_pdf()` ä¸­æ·»åŠ åˆ†æ”¯ï¼š
```python
if output_style == "markdown":
    return text_to_markdown(text, title, output_path)
```

---

## è°ƒè¯•æŠ€å·§

### 1. å¯ç”¨è°ƒè¯•æ¨¡å¼
```bash
# åœ¨ .env ä¸­è®¾ç½®
DEBUG_FLAG=true
LOG_LEVEL=DEBUG
```

### 2. æŸ¥çœ‹ç¬¬ä¸‰æ–¹åº“æ—¥å¿—
```bash
THIRD_PARTY_LOG_LEVEL=DEBUG python main.py
```

### 3. ä½¿ç”¨ pdb è°ƒè¯•
```python
import pdb; pdb.set_trace()
```

### 4. æ€§èƒ½åˆ†æ
```python
import cProfile
import pstats

profiler = cProfile.Profile()
profiler.enable()

# ä½ çš„ä»£ç 
process_audio(...)

profiler.disable()
stats = pstats.Stats(profiler)
stats.sort_stats('cumtime')
stats.print_stats(20)
```

---

## ç‰ˆæœ¬æ§åˆ¶ä¸éƒ¨ç½²

### Git å·¥ä½œæµ
```bash
git checkout -b feature/new-feature
git add .
git commit -m "feat: add new feature"
git push origin feature/new-feature
```

### Docker éƒ¨ç½²
```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
CMD ["python", "api.py"]
```

```yaml
version: '3.8'
services:
  avc-api:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./out:/app/out
      - ./download:/app/download
    env_file:
      - .env
```

---

## å®‰å…¨è€ƒè™‘

1. **API Keys**ï¼šæ°¸ä¸æäº¤ `.env` æ–‡ä»¶åˆ° Git
2. **æ–‡ä»¶ä¸Šä¼ **ï¼šéªŒè¯æ–‡ä»¶ç±»å‹å’Œå¤§å°ï¼Œä½¿ç”¨ä¸´æ—¶ç›®å½•
3. **LLM è¾“å…¥**ï¼šæ¸…ç†å’ŒéªŒè¯ç”¨æˆ·è¾“å…¥ï¼Œé™åˆ¶æ–‡æœ¬é•¿åº¦
4. **API è®¿é—®**ï¼šæ·»åŠ èº«ä»½éªŒè¯ï¼ˆJWT, API Keyï¼‰ã€é™æµå’Œé€Ÿç‡é™åˆ¶

---

## è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®  
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯  
3. ç¼–å†™æµ‹è¯•  
4. æäº¤ Pull Request  
5. ä»£ç å®¡æŸ¥  

---

## èµ„æºé“¾æ¥

- **é¡¹ç›®ä»“åº“**ï¼š[https://github.com/LogicShao/AutoVoiceCollation](https://github.com/LogicShao/AutoVoiceCollation)
- **FunASR æ–‡æ¡£**ï¼š[https://github.com/alibaba-damo-academy/FunASR](https://github.com/alibaba-damo-academy/FunASR)
- **FastAPI æ–‡æ¡£**ï¼š[https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/)

---

- **æœ€åæ›´æ–°**ï¼š2026-01-30
- **æ–‡æ¡£ç‰ˆæœ¬**ï¼š2.1ï¼ˆæ¨¡å—åŒ–æ¶æ„æ›´æ–°ç‰ˆï¼‰
- **çŠ¶æ€**ï¼šâœ… å·²æ›´æ–°ï¼Œåæ˜ å½“å‰æ¨¡å—åŒ–æ¶æ„ï¼Œé€‚ç”¨äºå›¢é˜Ÿåä½œä¸æ–°æˆå‘˜åŸ¹è®­

âœ… æœ¬æ–‡æ¡£å·²ä¼˜åŒ–ï¼Œé€‚åˆç”¨äºï¼š
- å›¢é˜Ÿå†…éƒ¨åŸ¹è®­
- CI/CD é…ç½®
- æ–°æˆå‘˜å…¥èŒ
- ä»£ç å®¡æŸ¥ä¸æ¶æ„è¯„å®¡
