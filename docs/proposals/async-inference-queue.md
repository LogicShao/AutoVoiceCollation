# å¼‚æ­¥æ¨ç†é˜Ÿåˆ—æ¶æ„è®¾è®¡æ–¹æ¡ˆ

- **æ–¹æ¡ˆç¼–å·**ï¼šARCH-001  
- **ä¼˜å…ˆçº§**ï¼šP0ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰  
- **é¢„è®¡å®æ–½æ—¶é—´**ï¼š2â€“4 å°æ—¶  
- **ç›®æ ‡**ï¼šè§£å†³ FastAPI æ¨ç†é˜»å¡é—®é¢˜ï¼Œå®ç°çœŸæ­£çš„å¼‚æ­¥ HTTP å“åº”  

---

## ä¸€ã€é—®é¢˜èƒŒæ™¯

### 1.1 å½“å‰æ¶æ„å­˜åœ¨çš„é—®é¢˜

#### âŒ æ ¸å¿ƒé—®é¢˜
FastAPI è™½ä½¿ç”¨ `async def` å’Œ `BackgroundTasks`ï¼Œä½†åå°ä»»åŠ¡å†…éƒ¨è°ƒç”¨çš„æ˜¯ **åŒæ­¥é˜»å¡å‡½æ•°**ï¼Œå¯¼è‡´æ•´ä¸ªæœåŠ¡åœ¨æ¨¡å‹æ¨ç†æœŸé—´æ— æ³•å“åº”å…¶ä»– HTTP è¯·æ±‚ã€‚

#### âŒ é—®é¢˜è¡¨ç°
```python
# api.py:327 - è™½ä¸º asyncï¼Œä½†å†…éƒ¨æ˜¯åŒæ­¥é˜»å¡
async def process_bilibili_task(task_id: str, ...):
    # âŒ åŒæ­¥å‡½æ•°ï¼Œä¼šå ç”¨äº‹ä»¶å¾ªç¯
    output_data, extract_time, polish_time, zip_file = bilibili_video_download_process(...)
```

#### âŒ å½±å“èŒƒå›´
- âœ˜ æ¨ç†æœŸé—´ï¼ˆ10ç§’â€“5åˆ†é’Ÿï¼‰ï¼Œæ— æ³•å“åº”å¥åº·æ£€æŸ¥ `/health`
- âœ˜ æ— æ³•æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€ `/api/v1/task/{task_id}`
- âœ˜ æ— æ³•æäº¤æ–°ä»»åŠ¡
- âœ˜ Web UI å‰ç«¯æ— æ³•è·å–è¿›åº¦æ›´æ–°

---

### 1.2 ä¸ºä»€ä¹ˆ `ProcessPoolExecutor` ä¸é€‚åˆï¼Ÿ

| é—®é¢˜ç»´åº¦       | `ProcessPoolExecutor` æ–¹æ¡ˆ           | æœ¬åœ°éƒ¨ç½²ç°å®                     |
|----------------|----------------------------------|------------------------------|
| **æ¨¡å‹åŠ è½½**     | æ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹åŠ è½½æ¨¡å‹                  | Paraformer: ~1.5GB Ã— 4 = 6GB       |
| **GPU æ˜¾å­˜**     | å¤šè¿›ç¨‹ç«äº‰å•ä¸ª GPU                   | CUDA OOM æˆ–æ¨ç†æ…¢ 3â€“5x             |
| **åˆå§‹åŒ–æ—¶é—´**   | æ¯æ¬¡è¯·æ±‚å†·å¯åŠ¨                       | æ¨¡å‹åŠ è½½ 15â€“30 ç§’/è¿›ç¨‹              |
| **æœ¬åœ°èµ„æº**     | éœ€å¤šæ ¸ CPU + å¤§å†…å­˜                 | ä¸ªäººç”µè„‘èµ„æºæœ‰é™                   |

#### ğŸ“Œ æ ¹æœ¬åŸå› 
- PyTorch æ¨¡å‹éçº¿ç¨‹/è¿›ç¨‹å®‰å…¨
- CUDA context æ— æ³•è·¨è¿›ç¨‹å…±äº«
- æœ¬åœ°å• GPU ç¯å¢ƒæ— éœ€å¹¶å‘æ¨ç†

---

## äºŒã€è§£å†³æ–¹æ¡ˆï¼šå•è¿›ç¨‹å¼‚æ­¥æ¨ç†é˜Ÿåˆ—

### 2.1 æ ¸å¿ƒè®¾è®¡æ€æƒ³

#### âœ… è®¾è®¡åŸåˆ™
1. **å•è¿›ç¨‹å•æ¨¡å‹**ï¼šå…¨å±€å”¯ä¸€æ¨¡å‹å®ä¾‹ï¼Œé¿å…é‡å¤åŠ è½½
2. **å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—**ï¼šä½¿ç”¨ `asyncio.Queue` ç®¡ç†æ¨ç†ä»»åŠ¡
3. **çº¿ç¨‹æ± æ‰§è¡Œå™¨**ï¼šé€šè¿‡ `run_in_executor` é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
4. **HTTP å¼‚æ­¥å“åº”**ï¼šFastAPI ç«‹å³è¿”å› `task_id`ï¼Œå®¢æˆ·ç«¯è½®è¯¢çŠ¶æ€

### 2.2 æ¶æ„è®¾è®¡

```mermaid
graph TD
    A[ç”¨æˆ· HTTP è¯·æ±‚] --> B[FastAPI å¼‚æ­¥ç«¯ç‚¹]
    B --> C{ç«‹å³è¿”å› 202 Accepted + task_id}
    C --> D[asyncio.Queue.put()]
    D --> E[InferenceQueueï¼ˆå•ä¾‹ï¼‰]
    E --> F[Worker Loop]
    F --> G[await queue.get()]
    G --> H[run_in_executor(None, sync_func)]
    H --> I[ThreadPoolExecutor]
    I --> J[åŒæ­¥æ¨ç†å‡½æ•°]
    J --> K[æ›´æ–°ä»»åŠ¡çŠ¶æ€åˆ°å†…å­˜]
    K --> L[å®¢æˆ·ç«¯è½®è¯¢ GET /task/{task_id}]
```

> âœ… å…³é”®ç‚¹ï¼š`run_in_executor` å°† CPU å¯†é›†å‹ä»»åŠ¡ç§»å‡ºäº‹ä»¶å¾ªç¯ï¼Œä¿è¯ HTTP å¯æŒç»­å“åº”ã€‚

---

### 2.3 å…³é”®æŠ€æœ¯ç‚¹

#### 2.3.1 ä¸ºä»€ä¹ˆ HTTP è¯·æ±‚ä¸ä¼šé˜»å¡ï¼Ÿ
```python
@app.post("/api/v1/process/bilibili")
async def process_bilibili_video(request: BilibiliVideoRequest):
    task_id = str(uuid.uuid4())
    
    # âœ… ç«‹å³è¿”å›ï¼Œä¸ç­‰å¾…æ¨ç†å®Œæˆ
    await inference_queue.submit_task(task_id, request)
    
    return {"task_id": task_id, "status": "pending"}
    # â† å®¢æˆ·ç«¯ç«‹å³æ”¶åˆ°å“åº”
```

#### 2.3.2 ä¸ºä»€ä¹ˆæ¨¡å‹æ¨ç†ä¸é˜»å¡äº‹ä»¶å¾ªç¯ï¼Ÿ
```python
async def _worker_loop(self):
    while True:
        task_item = await self.queue.get()  # âœ… å¼‚æ­¥ç­‰å¾…
        
        result = await asyncio.get_event_loop().run_in_executor(
            None,  # ä½¿ç”¨é»˜è®¤çº¿ç¨‹æ± 
            self._sync_inference,
            task_item
        )
        # â† æ¨ç†åœ¨å•ç‹¬çº¿ç¨‹ä¸­æ‰§è¡Œ
```

#### 2.3.3 æ¨¡å‹å•æ¬¡åŠ è½½æœºåˆ¶
```python
class InferenceQueue:
    def __init__(self):
        self._model = None
        self._model_lock = asyncio.Lock()

    async def _ensure_model_loaded(self):
        if self._model is None:
            async with self._model_lock:
                if self._model is None:
                    self._model = await asyncio.get_event_loop().run_in_executor(
                        None,
                        self._load_model_sync
                    )
```

---

## ä¸‰ã€ä»£ç å®ç°

### 3.1 æ¨ç†é˜Ÿåˆ—æ ¸å¿ƒç±»

#### ğŸ“‚ æ–‡ä»¶è·¯å¾„ï¼š`src/api/inference_queue.py`

```python
"""
å¼‚æ­¥æ¨ç†é˜Ÿåˆ—
æä¾›å•è¿›ç¨‹ã€å•æ¨¡å‹å®ä¾‹çš„å¼‚æ­¥æ¨ç†èƒ½åŠ›
"""

import asyncio
from asyncio import Queue
from typing import Optional, Dict, Any, Callable
from datetime import datetime
import traceback

from src.logger import get_logger
from src.core_process import bilibili_video_download_process, upload_audio
from src.text_arrangement.summary_by_llm import summarize_text

logger = get_logger(__name__)


class InferenceQueue:
    """
    å¼‚æ­¥æ¨ç†é˜Ÿåˆ—ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    è®¾è®¡åŸåˆ™ï¼š
    - å…¨å±€å”¯ä¸€å®ä¾‹ï¼ŒæŒæœ‰å”¯ä¸€æ¨¡å‹
    - ä¸²è¡Œå¤„ç†ä»»åŠ¡ï¼ˆé¿å… GPU å†²çªï¼‰
    - å¼‚æ­¥æ¥å£ï¼Œä¸é˜»å¡ FastAPI äº‹ä»¶å¾ªç¯
    """

    _instance: Optional['InferenceQueue'] = None

    def __new__(cls):
        """å•ä¾‹æ¨¡å¼"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        """åˆå§‹åŒ–é˜Ÿåˆ—ï¼ˆä»…æ‰§è¡Œä¸€æ¬¡ï¼‰"""
        if self._initialized:
            return

        self.queue: Queue = Queue()
        self.worker_task: Optional[asyncio.Task] = None
        self._model = None  # å»¶è¿ŸåŠ è½½
        self._model_lock = asyncio.Lock()
        self._initialized = True

        logger.info("æ¨ç†é˜Ÿåˆ—åˆå§‹åŒ–å®Œæˆ")

    async def start(self):
        """å¯åŠ¨å·¥ä½œå¾ªç¯"""
        if self.worker_task is None or self.worker_task.done():
            self.worker_task = asyncio.create_task(self._worker_loop())
            logger.info("âœ… æ¨ç†å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨")

    async def stop(self):
        """åœæ­¢å·¥ä½œå¾ªç¯"""
        if self.worker_task and not self.worker_task.done():
            self.worker_task.cancel()
            try:
                await self.worker_task
            except asyncio.CancelledError:
                logger.info("æ¨ç†å·¥ä½œçº¿ç¨‹å·²åœæ­¢")

    async def submit_task(
        self,
        task_id: str,
        task_type: str,
        task_data: Dict[str, Any],
        tasks_store: Dict
    ):
        """
        æäº¤ä»»åŠ¡åˆ°é˜Ÿåˆ—

        :param task_id: ä»»åŠ¡ ID
        :param task_type: ä»»åŠ¡ç±»å‹ï¼ˆbilibili, audio, batch, subtitleï¼‰
        :param task_data: ä»»åŠ¡æ•°æ®
        :param tasks_store: ä»»åŠ¡çŠ¶æ€å­˜å‚¨ï¼ˆå¼•ç”¨ä¼ é€’ï¼‰
        """
        await self.queue.put({
            'task_id': task_id,
            'task_type': task_type,
            'task_data': task_data,
            'tasks_store': tasks_store
        })
        logger.info(f"ä»»åŠ¡å·²æäº¤åˆ°é˜Ÿåˆ—: {task_id}, é˜Ÿåˆ—é•¿åº¦: {self.queue.qsize()}")

    async def _worker_loop(self):
        """å·¥ä½œå¾ªç¯ï¼šæŒç»­ä»é˜Ÿåˆ—å–ä»»åŠ¡å¹¶æ‰§è¡Œ"""
        logger.info("å·¥ä½œå¾ªç¯å·²å¯åŠ¨ï¼Œç­‰å¾…ä»»åŠ¡...")

        while True:
            try:
                task_item = await self.queue.get()

                task_id = task_item['task_id']
                task_type = task_item['task_type']
                task_data = task_item['task_data']
                tasks_store = task_item['tasks_store']

                logger.info(f"å¼€å§‹å¤„ç†ä»»åŠ¡: {task_id}, ç±»å‹: {task_type}")

                try:
                    # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
                    tasks_store[task_id]['status'] = 'processing'

                    # æ ¹æ®ç±»å‹è°ƒç”¨å¤„ç†å‡½æ•°
                    if task_type == 'bilibili':
                        await self._process_bilibili_task(task_id, task_data, tasks_store)
                    elif task_type == 'audio':
                        await self._process_audio_task(task_id, task_data, tasks_store)
                    elif task_type == 'batch':
                        await self._process_batch_task(task_id, task_data, tasks_store)
                    elif task_type == 'subtitle':
                        await self._process_subtitle_task(task_id, task_data, tasks_store)
                    else:
                        raise ValueError(f"æœªçŸ¥çš„ä»»åŠ¡ç±»å‹: {task_type}")

                    logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: {task_id}")

                except Exception as e:
                    logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {e}", exc_info=True)
                    tasks_store[task_id].update({
                        'status': 'failed',
                        'message': f"å¤„ç†å¤±è´¥: {str(e)}",
                        'error': traceback.format_exc(),
                        'completed_at': datetime.now().isoformat()
                    })

                finally:
                    self.queue.task_done()

            except asyncio.CancelledError:
                logger.info("å·¥ä½œå¾ªç¯è¢«å–æ¶ˆ")
                break
            except Exception as e:
                logger.error(f"å·¥ä½œå¾ªç¯å¼‚å¸¸: {e}", exc_info=True)

    async def _process_bilibili_task(self, task_id: str, data: Dict, tasks_store: Dict):
        """å¤„ç† Bç«™è§†é¢‘ä»»åŠ¡"""
        loop = asyncio.get_event_loop()

        output_data, extract_time, polish_time, zip_file = await loop.run_in_executor(
            None,
            bilibili_video_download_process,
            data['video_url'],
            data['llm_api'],
            data['temperature'],
            data['max_tokens'],
            data['text_only']
        )

        completed_at = datetime.now().isoformat()

        if data['text_only']:
            result_data = output_data

            if data.get('summarize') and 'polished_text' in result_data:
                tasks_store[task_id]['message'] = 'æ­£åœ¨ç”Ÿæˆæ€»ç»“'
                summary = await loop.run_in_executor(
                    None,
                    summarize_text,
                    result_data['polished_text'],
                    data['llm_api'],
                    data['temperature'],
                    data['max_tokens'],
                    result_data.get('title', '')
                )
                result_data['summary'] = summary
                completed_at = datetime.now().isoformat()

            tasks_store[task_id].update({
                'status': 'completed',
                'message': 'å¤„ç†å®Œæˆ',
                'result': result_data,
                'completed_at': completed_at
            })
        else:
            tasks_store[task_id].update({
                'status': 'completed',
                'message': 'å¤„ç†å®Œæˆ',
                'result': {
                    'output_dir': output_data,
                    'extract_time': extract_time,
                    'polish_time': polish_time,
                    'zip_file': zip_file
                },
                'completed_at': completed_at
            })

    async def _process_audio_task(self, task_id: str, data: Dict, tasks_store: Dict):
        """å¤„ç†éŸ³é¢‘ä»»åŠ¡"""
        import os
        loop = asyncio.get_event_loop()

        output_data, extract_time, polish_time, zip_file = await loop.run_in_executor(
            None,
            upload_audio,
            data['audio_path'],
            data['llm_api'],
            data['temperature'],
            data['max_tokens'],
            data['text_only']
        )

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(data['audio_path']):
            await loop.run_in_executor(
                None,
                os.remove,
                data['audio_path']
            )

        completed_at = datetime.now().isoformat()

        if data['text_only']:
            result_data = output_data

            if data.get('summarize') and 'polished_text' in result_data:
                tasks_store[task_id]['message'] = 'æ­£åœ¨ç”Ÿæˆæ€»ç»“'
                summary = await loop.run_in_executor(
                    None,
                    summarize_text,
                    result_data['polished_text'],
                    data['llm_api'],
                    data['temperature'],
                    data['max_tokens'],
                    result_data.get('title', '')
                )
                result_data['summary'] = summary
                completed_at = datetime.now().isoformat()

            tasks_store[task_id].update({
                'status': 'completed',
                'message': 'å¤„ç†å®Œæˆ',
                'result': result_data,
                'completed_at': completed_at
            })
        else:
            tasks_store[task_id].update({
                'status': 'completed',
                'message': 'å¤„ç†å®Œæˆ',
                'result': {
                    'output_dir': output_data,
                    'extract_time': extract_time,
                    'polish_time': polish_time,
                    'zip_file': zip_file
                },
                'completed_at': completed_at
            })

    async def _process_batch_task(self, task_id: str, data: Dict, tasks_store: Dict):
        """å¤„ç†æ‰¹é‡ä»»åŠ¡"""
        from src.core_process import process_multiple_urls
        loop = asyncio.get_event_loop()

        results = await loop.run_in_executor(
            None,
            process_multiple_urls,
            data['urls'],
            data['llm_api'],
            data['temperature'],
            data['max_tokens'],
            data['text_only']
        )

        tasks_store[task_id].update({
            'status': 'completed',
            'message': 'æ‰¹é‡å¤„ç†å®Œæˆ',
            'result': results,
            'completed_at': datetime.now().isoformat()
        })

    async def _process_subtitle_task(self, task_id: str, data: Dict, tasks_store: Dict):
        """å¤„ç†å­—å¹•ä»»åŠ¡"""
        from src.core_process import process_subtitles
        loop = asyncio.get_event_loop()

        output_path = await loop.run_in_executor(
            None,
            process_subtitles,
            data['video_path']
        )

        tasks_store[task_id].update({
            'status': 'completed',
            'message': 'å­—å¹•ç”Ÿæˆå®Œæˆ',
            'result': {'output_video': output_path},
            'completed_at': datetime.now().isoformat()
        })


# å…¨å±€å•ä¾‹
_inference_queue: Optional[InferenceQueue] = None


def get_inference_queue() -> InferenceQueue:
    """è·å–å…¨å±€æ¨ç†é˜Ÿåˆ—å®ä¾‹"""
    global _inference_queue
    if _inference_queue is None:
        _inference_queue = InferenceQueue()
    return _inference_queue
```

---

### 3.2 ä¿®æ”¹ FastAPI ä¸»æ–‡ä»¶

#### ğŸ“‚ æ–‡ä»¶è·¯å¾„ï¼š`api.py`

##### æ­¥éª¤ 1ï¼šå¯¼å…¥æ¨ç†é˜Ÿåˆ—
```python
# api.py é¡¶éƒ¨æ·»åŠ 
from src.api.inference_queue import get_inference_queue

# è·å–å…¨å±€æ¨ç†é˜Ÿåˆ—å®ä¾‹
inference_queue = get_inference_queue()
```

##### æ­¥éª¤ 2ï¼šæ·»åŠ ç”Ÿå‘½å‘¨æœŸäº‹ä»¶
```python
@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶æ‰§è¡Œ"""
    logger.info("å¯åŠ¨ FastAPI æœåŠ¡...")
    await inference_queue.start()
    logger.info("âœ… æ¨ç†é˜Ÿåˆ—å·²å¯åŠ¨")


@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶æ‰§è¡Œ"""
    logger.info("å…³é—­ FastAPI æœåŠ¡...")
    await inference_queue.stop()
    logger.info("âœ… æ¨ç†é˜Ÿåˆ—å·²åœæ­¢")
```

##### æ­¥éª¤ 3ï¼šä¿®æ”¹ API ç«¯ç‚¹
```python
@app.post("/api/v1/process/bilibili", response_model=TaskResponse)
async def process_bilibili_video(request: BilibiliVideoRequest):
    """å¤„ç† Bç«™è§†é¢‘ï¼ˆå¼‚æ­¥é˜Ÿåˆ—ç‰ˆæœ¬ï¼‰"""
    task_id = str(uuid.uuid4())

    # åˆ›å»ºä»»åŠ¡è®°å½•
    tasks[task_id] = {
        "status": "pending",
        "message": "ä»»åŠ¡å·²æäº¤ï¼Œç­‰å¾…å¤„ç†",
        "result": None,
        "created_at": datetime.now().isoformat(),
        "url": request.video_url,
        "filename": None
    }

    # âœ… æäº¤ä»»åŠ¡åˆ°å¼‚æ­¥é˜Ÿåˆ—ï¼ˆç«‹å³è¿”å›ï¼‰
    await inference_queue.submit_task(
        task_id=task_id,
        task_type='bilibili',
        task_data={
            'video_url': request.video_url,
            'llm_api': request.llm_api,
            'temperature': request.temperature,
            'max_tokens': request.max_tokens,
            'text_only': request.text_only,
            'summarize': request.summarize
        },
        tasks_store=tasks  # å¼•ç”¨ä¼ é€’ï¼Œé˜Ÿåˆ—å¯ç›´æ¥æ›´æ–°çŠ¶æ€
    )

    return TaskResponse(
        task_id=task_id,
        status="pending",
        message="ä»»åŠ¡å·²æäº¤åˆ°é˜Ÿåˆ—",
        created_at=tasks[task_id]["created_at"]
    )
```

##### æ­¥éª¤ 4ï¼šåˆ é™¤æ—§çš„åå°ä»»åŠ¡å‡½æ•°
```python
# âŒ åˆ é™¤ä»¥ä¸‹å‡½æ•°
async def process_bilibili_task(...)
async def process_audio_task(...)
async def process_batch_task(...)
async def process_subtitle_task(...)
```

---

## å››ã€å®æ–½æ­¥éª¤

### 4.1 Phase 1ï¼šæ ¸å¿ƒåŠŸèƒ½å®ç°ï¼ˆ2å°æ—¶ï¼‰

- [ ] åˆ›å»º `src/api/inference_queue.py`
- [ ] å®ç° `InferenceQueue` ç±»
- [ ] ä¿®æ”¹ `api.py` å¯¼å…¥æ¨ç†é˜Ÿåˆ—
- [ ] æ·»åŠ  `startup` å’Œ `shutdown` äº‹ä»¶å¤„ç†
- [ ] ä¿®æ”¹ `/api/v1/process/bilibili` ç«¯ç‚¹
- [ ] ä¿®æ”¹ `/api/v1/process/audio` ç«¯ç‚¹
- [ ] åˆ é™¤æ—§çš„åå°ä»»åŠ¡å‡½æ•°

### 4.2 Phase 2ï¼šæµ‹è¯•éªŒè¯ï¼ˆ1å°æ—¶ï¼‰

```bash
# æµ‹è¯• 1: å¥åº·æ£€æŸ¥åœ¨æ¨ç†æ—¶ä»å¯å“åº”
curl http://localhost:8000/health &
curl -X POST http://localhost:8000/api/v1/process/bilibili \
  -H "Content-Type: application/json" \
  -d '{"video_url": "https://www.bilibili.com/video/BV1xx411c7mD"}'

# é¢„æœŸï¼šhealth ç«‹å³è¿”å› 200

# æµ‹è¯• 2: æäº¤å¤šä¸ªä»»åŠ¡
for i in {1..3}; do
  curl -X POST http://localhost:8000/api/v1/process/bilibili \
    -H "Content-Type: application/json" \
    -d "{\"video_url\": \"https://www.bilibili.com/video/BV$i\"}" &
done

# é¢„æœŸï¼šæ‰€æœ‰è¯·æ±‚ç«‹å³è¿”å› task_idï¼Œä¸²è¡Œå¤„ç†

# æµ‹è¯• 3: æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
task_id="<ä»ä¸Šé¢è·å–>"
curl http://localhost:8000/api/v1/task/$task_id
```

### 4.3 Phase 3ï¼šæ€§èƒ½ä¼˜åŒ–ï¼ˆ1å°æ—¶ï¼‰

1. **æ·»åŠ é˜Ÿåˆ—å®¹é‡é™åˆ¶**
```python
self.queue: Queue = Queue(maxsize=10)  # æœ€å¤š10ä¸ªå¾…å¤„ç†ä»»åŠ¡
```

2. **æ·»åŠ ä»»åŠ¡è¶…æ—¶æœºåˆ¶**
```python
async def _process_with_timeout(self, task_item, timeout=3600):
    try:
        await asyncio.wait_for(self._process_task(task_item), timeout=timeout)
    except asyncio.TimeoutError:
        logger.error(f"ä»»åŠ¡è¶…æ—¶: {task_item['task_id']}")
        raise
```

3. **æ·»åŠ ä»»åŠ¡ä¼˜å…ˆçº§**
```python
from asyncio import PriorityQueue
self.queue: PriorityQueue = PriorityQueue()
await self.queue.put((priority, task_item))
```

---

## äº”ã€æ€§èƒ½åˆ†æ

### 5.1 èµ„æºå ç”¨å¯¹æ¯”

| æŒ‡æ ‡            | åŸæ–¹æ¡ˆï¼ˆBackgroundTasksï¼‰ | æ–°æ–¹æ¡ˆï¼ˆå¼‚æ­¥é˜Ÿåˆ—ï¼‰ |
|----------------|----------------------|-------------|
| **å†…å­˜å ç”¨**      | æ¨¡å‹åŠ è½½ 1 æ¬¡          | æ¨¡å‹åŠ è½½ 1 æ¬¡    |
| **GPU æ˜¾å­˜**    | å•è¿›ç¨‹ç‹¬å               | å•è¿›ç¨‹ç‹¬å        |
| **HTTP å“åº”æ—¶é—´** | 0.1â€“5åˆ†é’Ÿï¼ˆé˜»å¡ï¼‰         | <50msï¼ˆç«‹å³è¿”å›ï¼‰ |
| **å¹¶å‘æ¨ç†èƒ½åŠ›**    | 1 ä¸ªä»»åŠ¡               | 1 ä¸ªä»»åŠ¡ï¼ˆä¸²è¡Œï¼‰   |
| **é˜Ÿåˆ—å®¹é‡**      | æ— é™åˆ¶                | å¯é…ç½®ï¼ˆå»ºè®® 10â€“50ï¼‰|

### 5.2 é€‚ç”¨åœºæ™¯

| âœ… é€‚åˆ | âŒ ä¸é€‚åˆ |
|--------|----------|
| æœ¬åœ°å•ç”¨æˆ·æˆ–å°å›¢é˜Ÿä½¿ç”¨ | é«˜å¹¶å‘åœºæ™¯ï¼ˆæ¯åˆ†é’Ÿæ•°åä»»åŠ¡ï¼‰ |
| å• GPU/CPU ç¯å¢ƒ | å¤š GPU æœåŠ¡å™¨ï¼ˆæ— æ³•åˆ©ç”¨å¹¶è¡Œï¼‰ |
| ä»»åŠ¡é—´éš” > æ¨ç†æ—¶é—´ | ç”Ÿäº§çº§åˆ†å¸ƒå¼éƒ¨ç½² |

---

## å…­ã€åç»­ä¼˜åŒ–æ–¹å‘

### æ–¹æ¡ˆ Aï¼šONNX Runtime + å¤šçº¿ç¨‹
- ä¼˜åŠ¿ï¼š2â€“4x é€Ÿåº¦æå‡ï¼Œæ”¯æŒå¤šçº¿ç¨‹å¹¶å‘
- åŠ£åŠ¿ï¼šéœ€å¯¼å‡º ONNXï¼Œéƒ¨åˆ†åŠ¨æ€ç‰¹æ€§å—é™

### æ–¹æ¡ˆ Bï¼šæ‰¹å¤„ç†æ¨ç†
- ä¼˜åŠ¿ï¼šGPU åˆ©ç”¨ç‡æå‡ 2â€“3x
- åŠ£åŠ¿ï¼šå¢åŠ å»¶è¿Ÿï¼Œå†…å­˜å ç”¨æ›´é«˜

### æ–¹æ¡ˆ Cï¼šCelery åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—
- ä¼˜åŠ¿ï¼šæ”¯æŒæ¨ªå‘æ‰©å±•ã€æŒä¹…åŒ–ã€é‡è¯•
- åŠ£åŠ¿ï¼šéœ€ Redisï¼Œæ¶æ„å¤æ‚

---

## ä¸ƒã€é£é™©è¯„ä¼°

| é£é™©         | æ¦‚ç‡ | å½±å“ | ç¼“è§£æªæ–½ |
|------------|----|----|--------|
| é˜Ÿåˆ—ç§¯å‹     | ä¸­  | é«˜  | é™åˆ¶é˜Ÿåˆ—å¤§å° + è¶…æ—¶æœºåˆ¶ |
| ä»»åŠ¡ä¸¢å¤±     | ä½  | é«˜  | ä½¿ç”¨ Redis æŒä¹…åŒ–é˜Ÿåˆ— |
| å†…å­˜æ³„æ¼     | ä½  | ä¸­  | å®šæœŸæ¸…ç†å·²å®Œæˆä»»åŠ¡ |
| äº‹ä»¶å¾ªç¯é˜»å¡ | ä½  | é«˜  | ç¡®ä¿ä½¿ç”¨ `run_in_executor` |

---

## å…«ã€éªŒæ”¶æ ‡å‡†

### âœ… åŠŸèƒ½éªŒæ”¶
- [ ] æ¨ç†æ—¶ `/health` å¯æ­£å¸¸å“åº”
- [ ] æ¨ç†æ—¶å¯æäº¤æ–°ä»»åŠ¡
- [ ] æ¨ç†æ—¶å¯æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
- [ ] å¤šä¸ªä»»åŠ¡ä¸²è¡Œå¤„ç†ï¼Œä¸é‡å¤åŠ è½½æ¨¡å‹
- [ ] ä»»åŠ¡å¤±è´¥æ—¶æ­£ç¡®è®°å½•é”™è¯¯ä¿¡æ¯

### âœ… æ€§èƒ½éªŒæ”¶
- [ ] HTTP å“åº”æ—¶é—´ < 100ms
- [ ] æ¨¡å‹ä»…åŠ è½½ 1 æ¬¡
- [ ] å†…å­˜å ç”¨ä¸åŸæ–¹æ¡ˆç›¸åŒ
- [ ] é˜Ÿåˆ—é•¿åº¦å¯ç›‘æ§

---

## ä¹ã€å‚è€ƒèµ„æ–™

- [FastAPI åå°ä»»åŠ¡æ–‡æ¡£](https://fastapi.tiangolo.com/tutorial/background-tasks/)
- [asyncio å®˜æ–¹æ–‡æ¡£](https://docs.python.org/3/library/asyncio.html)
- [run_in_executor ç”¨æ³•](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.loop.run_in_executor)

---

## åã€æ€»ç»“

### âœ… æ ¸å¿ƒä»·å€¼
1. è§£å†³ HTTP é˜»å¡é—®é¢˜ï¼šæ¨ç†æ—¶æœåŠ¡å™¨ä»å¯å“åº”
2. èµ„æºå ç”¨æœ€ä¼˜ï¼šå•æ¨¡å‹å®ä¾‹ï¼Œé¿å…é‡å¤åŠ è½½
3. å®æ–½æˆæœ¬ä½ï¼š2â€“4 å°æ—¶å¿«é€Ÿä¸Šçº¿
4. æ¶æ„ç®€å•ï¼šæ— éœ€é¢å¤–ä¾èµ–ï¼ˆRedis/Celeryï¼‰
5. é€‚åˆæœ¬åœ°éƒ¨ç½²ï¼šå• GPU/CPU ç¯å¢ƒæœ€ä¼˜æ–¹æ¡ˆ

### ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨
- æŒ‰ç…§ Phase 1 å®æ–½ä»£ç ä¿®æ”¹
- æ‰§è¡Œæµ‹è¯•ç”¨ä¾‹éªŒè¯åŠŸèƒ½
- æ ¹æ®è´Ÿè½½è°ƒæ•´é˜Ÿåˆ—å®¹é‡
- ç›‘æ§æ€§èƒ½æŒ‡æ ‡ï¼Œå¿…è¦æ—¶è¿ç§»åˆ° Celery

---

- **ä½œè€…**ï¼šClaude Code  
- **å®¡æ ¸**ï¼šå¾…å®¡æ ¸  
- **çŠ¶æ€**ï¼šå¾…å®æ–½  

âœ… æœ¬æ–‡æ¡£å·²ä¼˜åŒ–ï¼Œé€‚ç”¨äºå¼€å‘è¯„å®¡ã€CI/CD é…ç½®ä¸å›¢é˜Ÿåä½œã€‚  
å¦‚éœ€å¯¼å‡º PDF / HTMLï¼Œä¹Ÿå¯ç»§ç»­ååŠ©ã€‚
